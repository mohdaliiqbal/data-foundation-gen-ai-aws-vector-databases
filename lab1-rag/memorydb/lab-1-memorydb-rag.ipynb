{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e87dc259",
   "metadata": {},
   "source": [
    "# RAG using MemoryDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cfd51d",
   "metadata": {},
   "source": [
    "[Retrieval Augmented Generation](https://arxiv.org/abs/2005.11401) is a process that combines retrieval-based models and generative models to enhance natural language generation by retrieving relevant information and incorporating it into the generation process. \n",
    "\n",
    "In this lab we are going to be writing a simple RAG application code that allows user to ask questions about various wines so they can make a purchasing decision. We will use the semantic search (*vector search*) capability within OpenSearch to retrieve the best matching wine reviews and provide that to LLM for answering user's questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c4d1e",
   "metadata": {},
   "source": [
    "## 1. Lab Pre-requisites\n",
    "\n",
    "#### a. Download and install python dependencies\n",
    "\n",
    "For this notebook we require the use of a few libraries. We'll use the Python clients for OpenSearch and SageMaker, and Python frameworks for text embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9fd01d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install redis pandas numpy sentence-transformers boto3 ipywidgets --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa614bc",
   "metadata": {},
   "source": [
    "### 3. Import libraries & initialize resource information\n",
    "The line below will import all the relevant libraries and modules used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1688f4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import redis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import boto3\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "from redis.commands.search.field import TextField, VectorField\n",
    "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
    "from redis.commands.search.query import Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3459fff5",
   "metadata": {},
   "source": [
    "#### Get CloudFormation stack output variables\n",
    "\n",
    "We have preconfigured a few resources by creating a cloudformation stack in the account. Information of these resources will be used within this lab. We are going to load some of the information variables here.\n",
    "\n",
    "You can ignore any \"PythonDeprecationWarning\" warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "81dc45a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S3BucketSecureURL': 'https://advanced-rag-memorydb-s3buckethosting-07kgl2bgs7kb.s3.amazonaws.com',\n",
       " 'DBSecret': 'arn:aws:secretsmanager:us-east-1:339712748691:secret:DBSecret-advanced-rag-memorydb-LGxrOB',\n",
       " 'BedrockBatchInferenceRoleArn': 'arn:aws:iam::339712748691:role/advanced-rag-memorydb-AmazonBedrockBatchInfererence-ftZQSE82GPg8',\n",
       " 'SageMakerNotebookURL': 'https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/notebook-instances/openNotebook/data-foundation-genai-nb?view=classic',\n",
       " 's3BucketTraining': 'advanced-rag-memorydb-s3buckettraining-trtanesjmc3m',\n",
       " 'Region': 'us-east-1',\n",
       " 'BedrockBatchInferenceRole': 'advanced-rag-memorydb-AmazonBedrockBatchInfererence-ftZQSE82GPg8',\n",
       " 'NotebookRole': 'advanced-rag-memorydb-NBRole-yqkVqFBWYrLo',\n",
       " 'NotebookRoleArn': 'arn:aws:iam::339712748691:role/advanced-rag-memorydb-NBRole-yqkVqFBWYrLo',\n",
       " 's3BucketHostingBucketName': 'advanced-rag-memorydb-s3buckethosting-07kgl2bgs7kb'}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Boto3 session\n",
    "session = boto3.Session()\n",
    "\n",
    "# Get the current region\n",
    "region = session.region_name\n",
    "\n",
    "cfn = boto3.client('cloudformation')\n",
    "\n",
    "# Method to obtain output variables from Cloudformation stack. \n",
    "def get_cfn_outputs(stackname):\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs\n",
    "\n",
    "## Setup variables to use for the rest of the demo\n",
    "cloudformation_stack_name = \"data-foundation-genai-aws-vector-databases\"\n",
    "\n",
    "outputs = get_cfn_outputs(cloudformation_stack_name)\n",
    "memorydb_endpoint = outputs['MemoryDBClusterEndpoint']\n",
    "sagemaker_notebook_url = outputs['SageMakerNotebookURL']\n",
    "\n",
    "# We will just print all the variables so you can easily copy if needed.\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6607721",
   "metadata": {},
   "source": [
    "## 3. Prepare data\n",
    "This lab combines semantic search with a generative model to present the retrieved data to the user . Below is a dataset of wine reviews, we'll sample this data set to recommend wines that resemble the user provided description.\n",
    "\n",
    "### Mandatory steps to download the data manually\n",
    "Within these labs you will need to download the dataset from various sources. One is Kaggle (You will need to create a free account):\n",
    "https://www.kaggle.com/datasets/christopheiv/winemagdata130k?select=winemag-data-130k-v2.json\n",
    "\n",
    "Click **Download** button on the dataset page above. Once downloaded in your laptop, you will resume with following steps.\n",
    "\n",
    "1. Execute the following cell to get URL to SageMaker Notebook. Click the URL to open sagemaker notebook instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9a9fc342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/notebook-instances/openNotebook/data-foundation-genai-nb?view=classic\" target=\"_blank\">Sagemaker notebook URL</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "link = f'<a href=\"{sagemaker_notebook_url}\" target=\"_blank\">Sagemaker notebook URL</a>'\n",
    "display(HTML(link))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a216887",
   "metadata": {},
   "source": [
    "2. Browse to the `retrieval-augment-generation` directory\n",
    "3. Click \"Upload\" to upload the zip downloaded from Kaggle\n",
    "4. Click \"New\" -> \"Terminal\" to open a terminal window\n",
    "5. Navigate to the `SageMaker/advanced-rag-amazon-opensearch/retrieval-augment-generation` directory by using following command. \n",
    "```\n",
    "cd SageMaker/advanced-rag-amazon-opensearch/retrieval-augment-generation\n",
    "```\n",
    "\n",
    "6. Unzip the uploaded zip file using following command\n",
    "\n",
    "```\n",
    "unzip archive.zip\n",
    "```\n",
    "\n",
    "Make sure the unzipped file `winmag-data-130k-v2.json` is in the same directory as this python notebook.\n",
    "\n",
    "After downloading and extracting the json file, execute the following cells to inspect the dataset, transform it into a pandas DataFrame, and sample a subset of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9847781",
   "metadata": {},
   "source": [
    "#### Sampling subset of the records to load into opensearch quickly\n",
    "Since the data is composed of 129,000 records, it could take some time to convert them into vectors and load them in a vector store. Therefore, we will take a subset (300 records) of our data. We will add a variable called record_id which corresponds to the index of the record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0b4a462a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>points</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>price</th>\n",
       "      <th>designation</th>\n",
       "      <th>variety</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>province</th>\n",
       "      <th>country</th>\n",
       "      <th>winery</th>\n",
       "      <th>record_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58623</td>\n",
       "      <td>89</td>\n",
       "      <td>Calera 2014 Pinot Noir (Central Coast)</td>\n",
       "      <td>Relatively light in the glass, this blend of n...</td>\n",
       "      <td>Matt Kettmann</td>\n",
       "      <td>@mattkettmann</td>\n",
       "      <td>28.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Central Coast</td>\n",
       "      <td>Central Coast</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>Calera</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49282</td>\n",
       "      <td>92</td>\n",
       "      <td>Wallis Family Estate 2008 Little Sister Red (D...</td>\n",
       "      <td>Dry and smooth as a fine old Scotch, with intr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Little Sister</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>Diamond Mountain District</td>\n",
       "      <td>Napa</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>Wallis Family Estate</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122398</td>\n",
       "      <td>84</td>\n",
       "      <td>Tucumen 2012 Cabernet Sauvignon (Mendoza)</td>\n",
       "      <td>Pointy cherry aromas initially suggest nail po...</td>\n",
       "      <td>Michael Schachner</td>\n",
       "      <td>@wineschach</td>\n",
       "      <td>16.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Mendoza</td>\n",
       "      <td>None</td>\n",
       "      <td>Mendoza Province</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Tucumen</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88318</td>\n",
       "      <td>90</td>\n",
       "      <td>Giant Steps 2013 Applejack Vineyard Pinot Noir...</td>\n",
       "      <td>Located in the upper Yarra, this site normally...</td>\n",
       "      <td>Joe Czerwinski</td>\n",
       "      <td>@JoeCz</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Applejack Vineyard</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Yarra Valley</td>\n",
       "      <td>None</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Giant Steps</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63322</td>\n",
       "      <td>87</td>\n",
       "      <td>Lenné Estate 2008 Pinot Noir</td>\n",
       "      <td>Held back and re-released in the spring of 201...</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>65.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>None</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>US</td>\n",
       "      <td>Lenné Estate</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  points                                              title  \\\n",
       "0   58623      89             Calera 2014 Pinot Noir (Central Coast)   \n",
       "1   49282      92  Wallis Family Estate 2008 Little Sister Red (D...   \n",
       "2  122398      84          Tucumen 2012 Cabernet Sauvignon (Mendoza)   \n",
       "3   88318      90  Giant Steps 2013 Applejack Vineyard Pinot Noir...   \n",
       "4   63322      87                       Lenné Estate 2008 Pinot Noir   \n",
       "\n",
       "                                         description        taster_name  \\\n",
       "0  Relatively light in the glass, this blend of n...      Matt Kettmann   \n",
       "1  Dry and smooth as a fine old Scotch, with intr...               None   \n",
       "2  Pointy cherry aromas initially suggest nail po...  Michael Schachner   \n",
       "3  Located in the upper Yarra, this site normally...     Joe Czerwinski   \n",
       "4  Held back and re-released in the spring of 201...       Paul Gregutt   \n",
       "\n",
       "  taster_twitter_handle  price         designation                   variety  \\\n",
       "0         @mattkettmann   28.0                None                Pinot Noir   \n",
       "1                  None   45.0       Little Sister  Bordeaux-style Red Blend   \n",
       "2           @wineschach   16.0                None        Cabernet Sauvignon   \n",
       "3                @JoeCz   42.0  Applejack Vineyard                Pinot Noir   \n",
       "4           @paulgwine    65.0                None                Pinot Noir   \n",
       "\n",
       "                    region_1       region_2          province    country  \\\n",
       "0              Central Coast  Central Coast        California         US   \n",
       "1  Diamond Mountain District           Napa        California         US   \n",
       "2                    Mendoza           None  Mendoza Province  Argentina   \n",
       "3               Yarra Valley           None          Victoria  Australia   \n",
       "4          Willamette Valley           None            Oregon         US   \n",
       "\n",
       "                 winery  record_id  \n",
       "0                Calera          1  \n",
       "1  Wallis Family Estate          2  \n",
       "2               Tucumen          3  \n",
       "3           Giant Steps          4  \n",
       "4          Lenné Estate          5  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Following code will not work without completing the above steps \n",
    "\n",
    "#Following code will not work without completing the above steps \n",
    "df = pd.read_json('winemag-data-130k-v2.json')\n",
    "df_sample = df.sample(300,random_state=37).reset_index()\n",
    "df_sample['record_id'] = range(1, len(df_sample) + 1)\n",
    "df_sample[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54a349",
   "metadata": {},
   "source": [
    "## 4. Create a connection with MemoryDB cluster.\n",
    "Next, we'll use Python API to set up connection with MemoryDB Cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "405e0e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect to Redis\n",
    "redis_conn = redis.RedisCluster(\n",
    "    host='your memorydb endpoint here',\n",
    "    port=6379,\n",
    "    ssl=True,\n",
    "    decode_responses=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c0fe3d",
   "metadata": {},
   "source": [
    "## 5. Using Amazon Bedrock titan embedding to convert text to vectors\n",
    "Amazon Bedrock offers Amazon titan embedding v2 model that generates vector embeddings for text. This model will be used as our primary model for embeddings.\n",
    "\n",
    "#### Helper method to invoke Titan embedding model in Amazon Bedrock\n",
    "Creating a helper method in python to invoke Amazon Titan embedding model from Amazon Bedrock to generate embeddings. We will update `df_sample` data frame and add a new column called `embedding` in it. Once this cell is executed, our data frame will be ready to load into opensearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "78d8cf6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>points</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>price</th>\n",
       "      <th>designation</th>\n",
       "      <th>variety</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>province</th>\n",
       "      <th>country</th>\n",
       "      <th>winery</th>\n",
       "      <th>record_id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58623</td>\n",
       "      <td>89</td>\n",
       "      <td>Calera 2014 Pinot Noir (Central Coast)</td>\n",
       "      <td>Relatively light in the glass, this blend of n...</td>\n",
       "      <td>Matt Kettmann</td>\n",
       "      <td>@mattkettmann</td>\n",
       "      <td>28.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Central Coast</td>\n",
       "      <td>Central Coast</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>Calera</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.076181315, -0.026136676, 0.0055211196, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49282</td>\n",
       "      <td>92</td>\n",
       "      <td>Wallis Family Estate 2008 Little Sister Red (D...</td>\n",
       "      <td>Dry and smooth as a fine old Scotch, with intr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Little Sister</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>Diamond Mountain District</td>\n",
       "      <td>Napa</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>Wallis Family Estate</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.06627269, 0.032748785, 0.0018651306, 0.033...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122398</td>\n",
       "      <td>84</td>\n",
       "      <td>Tucumen 2012 Cabernet Sauvignon (Mendoza)</td>\n",
       "      <td>Pointy cherry aromas initially suggest nail po...</td>\n",
       "      <td>Michael Schachner</td>\n",
       "      <td>@wineschach</td>\n",
       "      <td>16.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Mendoza</td>\n",
       "      <td>None</td>\n",
       "      <td>Mendoza Province</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Tucumen</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.09669418, 0.0404683, -0.023994481, 0.02829...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88318</td>\n",
       "      <td>90</td>\n",
       "      <td>Giant Steps 2013 Applejack Vineyard Pinot Noir...</td>\n",
       "      <td>Located in the upper Yarra, this site normally...</td>\n",
       "      <td>Joe Czerwinski</td>\n",
       "      <td>@JoeCz</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Applejack Vineyard</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Yarra Valley</td>\n",
       "      <td>None</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Giant Steps</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.03002267, 0.04153512, -0.0007547992, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63322</td>\n",
       "      <td>87</td>\n",
       "      <td>Lenné Estate 2008 Pinot Noir</td>\n",
       "      <td>Held back and re-released in the spring of 201...</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>65.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>None</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>US</td>\n",
       "      <td>Lenné Estate</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.0426923, 0.025679579, -0.0015548182, 0.013...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  points                                              title  \\\n",
       "0   58623      89             Calera 2014 Pinot Noir (Central Coast)   \n",
       "1   49282      92  Wallis Family Estate 2008 Little Sister Red (D...   \n",
       "2  122398      84          Tucumen 2012 Cabernet Sauvignon (Mendoza)   \n",
       "3   88318      90  Giant Steps 2013 Applejack Vineyard Pinot Noir...   \n",
       "4   63322      87                       Lenné Estate 2008 Pinot Noir   \n",
       "\n",
       "                                         description        taster_name  \\\n",
       "0  Relatively light in the glass, this blend of n...      Matt Kettmann   \n",
       "1  Dry and smooth as a fine old Scotch, with intr...               None   \n",
       "2  Pointy cherry aromas initially suggest nail po...  Michael Schachner   \n",
       "3  Located in the upper Yarra, this site normally...     Joe Czerwinski   \n",
       "4  Held back and re-released in the spring of 201...       Paul Gregutt   \n",
       "\n",
       "  taster_twitter_handle  price         designation                   variety  \\\n",
       "0         @mattkettmann   28.0                None                Pinot Noir   \n",
       "1                  None   45.0       Little Sister  Bordeaux-style Red Blend   \n",
       "2           @wineschach   16.0                None        Cabernet Sauvignon   \n",
       "3                @JoeCz   42.0  Applejack Vineyard                Pinot Noir   \n",
       "4           @paulgwine    65.0                None                Pinot Noir   \n",
       "\n",
       "                    region_1       region_2          province    country  \\\n",
       "0              Central Coast  Central Coast        California         US   \n",
       "1  Diamond Mountain District           Napa        California         US   \n",
       "2                    Mendoza           None  Mendoza Province  Argentina   \n",
       "3               Yarra Valley           None          Victoria  Australia   \n",
       "4          Willamette Valley           None            Oregon         US   \n",
       "\n",
       "                 winery  record_id  \\\n",
       "0                Calera          1   \n",
       "1  Wallis Family Estate          2   \n",
       "2               Tucumen          3   \n",
       "3           Giant Steps          4   \n",
       "4          Lenné Estate          5   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.076181315, -0.026136676, 0.0055211196, -0....  \n",
       "1  [-0.06627269, 0.032748785, 0.0018651306, 0.033...  \n",
       "2  [-0.09669418, 0.0404683, -0.023994481, 0.02829...  \n",
       "3  [-0.03002267, 0.04153512, -0.0007547992, -0.05...  \n",
       "4  [-0.0426923, 0.025679579, -0.0015548182, 0.013...  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "\n",
    "bedrock_client = boto3.client(\n",
    "    \"bedrock-runtime\", \n",
    "    region, \n",
    "    endpoint_url=f\"https://bedrock-runtime.{region}.amazonaws.com\"\n",
    ")\n",
    "\n",
    "\n",
    "def add_embeddings_to_df(df, text_column):\n",
    "\n",
    "    # Create an empty list to store embeddings\n",
    "    embeddings = []\n",
    "\n",
    "    # Iterate over the text in the specified column\n",
    "    for text in df[text_column]:\n",
    "        embedding = embed_phrase(text)\n",
    "        embeddings.append(embedding)\n",
    "        \n",
    "\n",
    "    # Add the embeddings as a new column to the DataFrame\n",
    "    df['embedding'] = embeddings\n",
    "\n",
    "    return df\n",
    "\n",
    "def embed_phrase( text ):\n",
    "        \n",
    "    model_id = \"amazon.titan-embed-text-v2:0\"  # \n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "\n",
    "    # Prepare the request payload\n",
    "    request_payload = json.dumps({\"inputText\": text})\n",
    "\n",
    "\n",
    "    response = bedrock_client.invoke_model(body=request_payload, modelId=model_id, accept=accept, contentType=contentType)\n",
    "\n",
    "    # Extract the embedding from the response\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "\n",
    "    # Append the embedding to the list\n",
    "    embedding = response_body.get(\"embedding\")\n",
    "    return embedding\n",
    "\n",
    "df_sample = add_embeddings_to_df(df_sample, 'description')\n",
    "\n",
    "df_sample[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b875df0b",
   "metadata": {},
   "source": [
    "#### Let's try to create an embedding of a simple input text\n",
    "You can see its an array of floating point numbers. While it does not make sense to human eye/brain, this array of numbers captures the semantics and knowledge of the text and that can be later used to compare two different text blocks. This method will be used to convert our query to a vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "43874004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_text='A wine that pairs well with turkey breast?'\n",
      "embedding[:10]=[-0.047978073, -0.015916897, 0.0042634546, -0.0121082105, -0.040701777, -0.0054003755, -0.010118598, -0.025125958, -0.009152215, -0.07685587]\n"
     ]
    }
   ],
   "source": [
    "## Create an vector embedding for input text\n",
    "input_text = \"A wine that pairs well with turkey breast?\"\n",
    "\n",
    "embedding = embed_phrase(input_text)\n",
    "\n",
    "#printing text and embedding\n",
    "\n",
    "print(f\"{input_text=}\")\n",
    "\n",
    "#only printing first 10 dimensions of the 1024 dimension vector \n",
    "print(f\"{embedding[:10]=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaabc1e",
   "metadata": {},
   "source": [
    "## 7. Create a index in Amazon MemoryDB \n",
    "Whereas we previously created an index with 2-3 fields, this time we'll define the index with multiple fields: the vectorization of the `description` field, and all others present within the dataset.\n",
    "\n",
    "To create the index, we first define the index in JSON, then use the redis client we initiated ealier to create the vector index in MemoryDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5eba5754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define schema\n",
    "schema = (\n",
    "    TextField(\"description\"),\n",
    "    TextField(\"winery\"),\n",
    "    TextField(\"country\"),\n",
    "    TextField(\"designation\"),\n",
    "    TextField(\"variety\"),\n",
    "    TextField(\"points\"),\n",
    "    VectorField(\"embedding\", \"FLAT\", {\"TYPE\": \"FLOAT32\", \"DIM\": 1024, \"DISTANCE_METRIC\": \"COSINE\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e84514d",
   "metadata": {},
   "source": [
    "Using the above index definition, we now need to create the index in Amazon MemoryDB. Running this cell will recreate the index if you have already executed this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "464b0ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redis_conn.ft('wine_index').create_index(fields=schema, definition=IndexDefinition(prefix=['doc:'], index_type=IndexType.HASH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7007735",
   "metadata": {},
   "source": [
    "Let's verify the created index information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1f71659d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index_name': 'wine_index',\n",
       " 'creation_timestamp': 1720453681190,\n",
       " 'key_type': 'HASH',\n",
       " 'key_prefixes': ['doc:'],\n",
       " 'fields': [['identifier',\n",
       "   'country',\n",
       "   'field_name',\n",
       "   'country',\n",
       "   'type',\n",
       "   'TEXT',\n",
       "   'option',\n",
       "   ''],\n",
       "  ['identifier',\n",
       "   'description',\n",
       "   'field_name',\n",
       "   'description',\n",
       "   'type',\n",
       "   'TEXT',\n",
       "   'option',\n",
       "   ''],\n",
       "  ['identifier',\n",
       "   'designation',\n",
       "   'field_name',\n",
       "   'designation',\n",
       "   'type',\n",
       "   'TEXT',\n",
       "   'option',\n",
       "   ''],\n",
       "  ['identifier',\n",
       "   'embedding',\n",
       "   'field_name',\n",
       "   'embedding',\n",
       "   'type',\n",
       "   'VECTOR',\n",
       "   'option',\n",
       "   '',\n",
       "   'vector_params',\n",
       "   ['algorithm',\n",
       "    'FLAT',\n",
       "    'data_type',\n",
       "    'FLOAT32',\n",
       "    'dimension',\n",
       "    1024,\n",
       "    'distance_metric',\n",
       "    'COSINE',\n",
       "    'initial_capacity',\n",
       "    1000,\n",
       "    'current_capacity',\n",
       "    1000,\n",
       "    'block_size',\n",
       "    1024]],\n",
       "  ['identifier',\n",
       "   'points',\n",
       "   'field_name',\n",
       "   'points',\n",
       "   'type',\n",
       "   'TEXT',\n",
       "   'option',\n",
       "   ''],\n",
       "  ['identifier',\n",
       "   'variety',\n",
       "   'field_name',\n",
       "   'variety',\n",
       "   'type',\n",
       "   'TEXT',\n",
       "   'option',\n",
       "   ''],\n",
       "  ['identifier',\n",
       "   'winery',\n",
       "   'field_name',\n",
       "   'winery',\n",
       "   'type',\n",
       "   'TEXT',\n",
       "   'option',\n",
       "   '']],\n",
       " 'space_usage': 4397354,\n",
       " 'fulltext_space_usage': 159586,\n",
       " 'vector_space_usage': 4237768,\n",
       " 'num_docs': 300,\n",
       " 'num_indexed_vectors': 300,\n",
       " 'current_lag': 0,\n",
       " 'backfill_status': 'Completed'}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redis_conn.ft('wine_index').info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0040992c",
   "metadata": {},
   "source": [
    "## 8. Load the raw data into the Index\n",
    "Next, let's load the wine review data and embedding into the index we've just created. Notice that we will store our embedding in `description_vector` field which will later be used for KNN search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "53863660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(client, df):\n",
    "    p = client.pipeline(transaction=False)\n",
    "    for i, row in df.iterrows():\n",
    "        key = f\"doc:{row['record_id']}\"\n",
    "        data = {\n",
    "            \"description\": row['description'] or '',\n",
    "            \"winery\": row['winery'] or '',\n",
    "            \"country\": row['country'] or '',\n",
    "            \"designation\": row['designation'] or '',\n",
    "            \"variety\": row['variety'] or '',\n",
    "            \"points\": row['points'] or '',\n",
    "            \"embedding\": np.array(row['embedding'], dtype=np.float32).tobytes()\n",
    "        }\n",
    "        p.hset(key, mapping=data)\n",
    "    p.execute()\n",
    "\n",
    "# loading data\n",
    "load_vectors(redis_conn, df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fad674",
   "metadata": {},
   "source": [
    "To validate the load, we'll query the number of documents number in the index. We should have 300 hits in the index, or however many was specified earlier in sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "05ed0b71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records found: 300.\n"
     ]
    }
   ],
   "source": [
    "result = redis_conn.ft('wine_index').search('*')\n",
    "print(\"Records found: %d.\" % result.total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9b827c",
   "metadata": {},
   "source": [
    "## 9. Search vector\n",
    "\n",
    "Now we can define a helper function to execute the search query for us to find a wine whose review most closely matches the requested description. `retrieve_opensearch_with_semantic_search` embeds the search phrase, searches the index for the closest matching vector, and returns the top result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d8ed4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_vectors(client, query, k=3):\n",
    "    query_vector = np.array(embed_phrase(query), dtype=np.float32).tobytes()\n",
    "\n",
    "    search_query = f\"*=>[KNN {k} @embedding $query_vector AS score]\"\n",
    "    params = {\"query_vector\": query_vector}\n",
    "    result = client.ft('wine_index').search(\n",
    "        Query(search_query)\n",
    "        .sort_by(\"score\")\n",
    "        .return_fields(\"description\", \"winery\", \"country\", \"designation\", \"variety\", \"points\")\n",
    "        .dialect(2),\n",
    "        query_params=params\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    for doc in result.docs:\n",
    "        results.append({\n",
    "            \"description\": doc.description,\n",
    "            \"winery\": doc.winery,\n",
    "            \"country\": doc.country,\n",
    "            \"designation\": doc.designation,\n",
    "            \"variety\": doc.variety,\n",
    "            \"points\": doc.points\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f6820a",
   "metadata": {},
   "source": [
    "Use the semantic search to get similar records with the sample question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1d529077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'description': \"There's a distinctive mineral aspect that sets this wine apart. Those aromas recall white stone or slate and enhance the wine's elegance and food pairing potential. The mouth is bright and ripe with red cherry and fresh berry notes on the close. It would pair well with braised meat.\", 'winery': 'Ruffino', 'country': 'Italy', 'designation': 'Riserva Ducale Oro', 'variety': 'Sangiovese', 'points': '91'}, {'description': 'With fairly muted fruit flavors and a hint of green pepper, this lighter-bodied and easy-drinking wine will pair well with most meat or chicken entrées. Flash-pasteurized and mevushal, this is a blend of 50% Cab, 30% Merlot and 20% Shiraz.', 'winery': 'Recanati', 'country': 'Israel', 'designation': 'Yasmin Red Kosher', 'variety': 'Red Blend', 'points': '84'}, {'description': \"With juicy acidity and tart flavors of cranberries and sour-cherry candy, this is a Pinot Noir to drink now. It's dry and a little austere, but rich beef and lamb dishes will coax out the fruit.\", 'winery': 'Seagrape', 'country': 'US', 'designation': 'Jump Up', 'variety': 'Pinot Noir', 'points': '88'}]\n"
     ]
    }
   ],
   "source": [
    "query = \"Best Australian wine that goes great with steak?\"\n",
    "\n",
    "results = search_vectors(redis_conn, query)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98987279",
   "metadata": {},
   "source": [
    "## 10. Prepare a method to call Amazon Bedrock - Anthropic Claude Sonnet model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd47ade",
   "metadata": {},
   "source": [
    "Now we will define a function to call LLM to answer user's question. As LLM is trained with static data, and it does not have our wine review knowledge. While it may be able to answer, it may not be an answer that a business prefers. For example. in our case, we would not want to recommend a wine that we do not stock. So the recommendation has to be one of the wines from our collection i.e. 300 reviews that we loaded. \n",
    "\n",
    "After defining this function we will call it to see how LLM answers questions without the wine review data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7fd66920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm(system, user_question):\n",
    "    model_id = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "    payload = json.dumps({\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 10000,\n",
    "        \"system\": system,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": user_question}]\n",
    "    })\n",
    "    response = bedrock_client.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=payload.encode('utf-8'),\n",
    "        accept=\"application/json\",\n",
    "        contentType=\"application/json\"\n",
    "    )\n",
    "    response_body = json.loads(response['body'].read())\n",
    "    return response_body['content'][0]['text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb63ed8",
   "metadata": {},
   "source": [
    "Let's check the generated result for a wine recommendation. It may not be one of the wine that we stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "57b5542b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recommened wine from LLM without RAG: \n",
      "For a perfect pairing with a juicy steak, I would recommend a bold and full-bodied Australian Shiraz from the renowned Barossa Valley region. This deeply colored red wine exudes rich aromas of blackberry, plum, and hints of spice, complemented by velvety tannins and a luscious mouthfeel. The intense flavors of dark fruits, mocha, and a touch of eucalyptus perfectly complement the savory essence of a well-grilled steak, creating a harmonious and indulgent experience for the palate.\n",
      "\n",
      "Wine name: Penfolds Bin 28 Kalimna Shiraz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def query_llm_without_rag(question):\n",
    "    \n",
    "    #Claude model has 2 parts of the prompt. System prompt guides the model what role to play\n",
    "    system_prompt = f\"You are a sommelier that uses their vast knowledge of wine to make great recommendations people will enjoy.\"\n",
    "    \n",
    "    #User prompt is the engineer prompt that has the context that model should reference to answer questions\n",
    "    user_prompt = (\n",
    "        f\" As a sommelier, you must include the wine variety, the country of origin, \"\n",
    "        f\"and a colorful description relating to the customer question.\"\n",
    "        f\"\\n Customer question: {question}\"\n",
    "        f\"\\n Please provide name of the wine at the end of the answer, in a new line, in format Wine name: <wine name>\"\n",
    "    )\n",
    "    return query_llm(system_prompt, user_prompt)\n",
    "\n",
    "\n",
    "question_on_wine=\"Best Australian wine that goes great with steak?\"\n",
    "\n",
    "print(f\"The recommened wine from LLM without RAG: \\n{query_llm_without_rag(question_on_wine)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c5a4c",
   "metadata": {},
   "source": [
    "#### Testing for hallucination. \n",
    "Let's copy the wine name from the last line and past it in the question variable below to see if we have this wine in our stock. Please review the list of wines that are returned. They may be from portugal but not exactly the one we have been recommended by the model.\n",
    "\n",
    "__Note:__ If you do not see the same wine name in the `wine_name` variable below, you should replace it so we can verify that the wine recommended is not in our index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ff031f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching wine records in our reviews:\n",
      "\"The Penfolds Bin 389 Kalimna Shiraz is a bold and opulent wine from the iconic Australian winery. This Shiraz variety hails from the sun-drenched Kalimna vineyard in the Barossa Valley, renowned for producing structured and full-bodied red wines. The wine exudes deep, inky purple hues and alluring aromas of ripe blackberries, plums, and notes of dark chocolate and warm spices. On the palate, it unveils layers of concentrated black fruit flavors, complemented by hints of vanilla, tobacco, and well-integrated oak. The velvety tannins provide a firm backbone, while the lingering finish leaves a lasting impression of opulence and finesse.\\n\\nWine name: Penfolds Bin 389 Kalimna Shiraz\"\n"
     ]
    }
   ],
   "source": [
    "wine_name = \"Penfolds Bin 389 Kalimna Shiraz\"\n",
    "example_request = query_llm_without_rag(wine_name)\n",
    "print(\"Matching wine records in our reviews:\")\n",
    "print(json.dumps(example_request, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d9e654",
   "metadata": {},
   "source": [
    "## 11. Retrieval Augmented Generation\n",
    "---\n",
    "To resolve LLM hallunination problem, we can more context to LLM so that LLM can use context information to fine the model and generated factual result. RAG is one of the solution to the LLM hallucination. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fa5564",
   "metadata": {},
   "source": [
    "#### Create a prompt for the LLM using the search results from OpenSearch (RAG)\n",
    "\n",
    "We will be using the Anthropic Sonnet model with one-shot prompting technique. Within instructions to the model in the prompt, we will provide a sample wine review and how model should use to answer user's question. At the end of the prompt wine reviews retrieved from Opensearch will be included for model to use. \n",
    "\n",
    "Before querying the model, the below function `generate_rag_based_system_prompt` is used to put together user prompt. The function takes in an input string to search the MemoryDB cluster for a matching wine, then compose the user prompt for LLM. \n",
    "\n",
    "System prompt defines the role that LLM plays.\n",
    "\n",
    "User prompt contains the instructions and the context information that LLM model uses to answer user's question.\n",
    "\n",
    "The prompt is in the following format:\n",
    "\n",
    "**SYSTEM PROMPT:**\n",
    "\n",
    "```\n",
    "You are a sommelier that uses their vast knowledge of wine to make great recommendations people will enjoy. \n",
    "```\n",
    "\n",
    "\n",
    "**USER PROMPT**\n",
    "```\n",
    "As a sommelier, you must include the wine variety, the country of origin, and a colorful description relating to the user's question.\n",
    "\n",
    "Data:{'description': 'This perfumey white dances in intense and creamy layers of stone fruit and vanilla, remaining vibrant and balanced from start to finish. The generous fruit is grown in the relatively cooler Oak Knoll section of the Napa Valley. This should develop further over time and in the glass.', 'winery': 'Darioush', 'points': 92, 'designation': None, 'country': 'US'}\n",
    "\n",
    "Recommendation:I have a wonderful wine for you. It's a dry, medium bodied white wine from Darioush winery in the Oak Knoll section of Napa Valley, US. It has flavors of vanilla and oak. It scored 92 points in wine spectator.\n",
    "\n",
    "Data: {retrieved_documents}\n",
    "\n",
    "Question from the user as is\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26aa75c",
   "metadata": {},
   "source": [
    "### package the prompt and query the LLM\n",
    "We will create a final function to query the LLM with the prompt. `query_llm_with_rag` is a function that calls LLM in a RAG.\n",
    "\n",
    "`query_llm_with_rag` combines everything we've done in this module. It does all of the following:\n",
    "- searches the vector index for the relevant wine with \"description vector\"\n",
    "- generate an LLM prompt from the search results\n",
    "- queriy the LLM with RAG for a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "073b9d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm_with_rag(user_question):\n",
    "    retrieved_documents = search_vectors(redis_conn, user_question, 10)\n",
    "    one_shot_description_example = \"{'description': 'This perfumey white dances in intense and creamy layers of stone fruit and vanilla, remaining vibrant and balanced from start to finish. The generous fruit is grown in the relatively cooler Oak Knoll section of the Napa Valley. This should develop further over time and in the glass.', 'winery': 'Darioush', 'points': 92, 'designation': None, 'country': 'US'}\"\n",
    "    one_shot_response_example = \"I have a wonderful wine for you. It's a dry, medium bodied white wine from Darioush winery in the Oak Knoll section of Napa Valley, US. It has flavors of vanilla and oak. It scored 92 points in wine spectator.\"\n",
    "    system_prompt = \"You are a sommelier that uses vast knowledge of wine to make great recommendations people will enjoy.\"\n",
    "    user_prompt = (\n",
    "        f\"As a sommelier, you must include the wine variety, the country of origin, and a colorful description relating to the user question. You are must pick a wine in \\\"Wine data\\\" section only, one that matches best the customer question. Do not suggest anything outside of the wine data provided. You don't necessarily have to pick the top rated wine if its not best suited for customer question.\\n\"\n",
    "        f\"Example Wine data: {one_shot_description_example} \\n Example Recommendation: {one_shot_response_example} \\n\"\n",
    "        f\"Wine data: {retrieved_documents}\\n\"\n",
    "        f\"Customer Question: {user_question}\\n\"\n",
    "    )\n",
    "    response = query_llm(system_prompt, user_prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de7273",
   "metadata": {},
   "source": [
    "#### And finally, let's call the function and get a wine recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a1ccf971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately, there are no Australian wines in the provided wine data to recommend for pairing with steak. However, I can suggest an excellent option from the data:\n",
      "\n",
      "I would recommend the Ruffino Riserva Ducale Oro Sangiovese from Italy. It's a dry, medium-bodied red wine with a distinctive mineral quality that enhances its elegance and food pairing potential. The wine has bright red cherry and fresh berry notes that would complement the flavors of a nicely grilled steak. With a score of 91 points, this Sangiovese from the renowned Ruffino winery in Italy would be an excellent choice to pair with your steak dinner.\n"
     ]
    }
   ],
   "source": [
    "question_on_wine=\"Best Australian wine that goes great with steak?\"\n",
    "recommendation = query_llm_with_rag(question_on_wine)\n",
    "print(recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc562a1e",
   "metadata": {},
   "source": [
    "#### Let's change it to Italian wine - it should produce a matching result.\n",
    "We will call the same method again to see if there is an italian wine in our catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ee791272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For pairing with a delicious steak dinner, I would recommend the Damilano Cannubi Barolo from Italy. This Nebbiolo wine from the prized Cannubi cru in northern Italy offers intense flavors of ripe berries, tight tannins, power and personality that can stand up to a rich steak. The wine's description notes \"Pair this Barolo with risotto topped with thinly shaved truffles\", suggesting it has the bold character to complement beef dishes exceptionally well. With a stellar 92 point rating, the Damilano Cannubi Barolo from the renowned Barolo region of Italy would make an excellent pairing for your steak.\n"
     ]
    }
   ],
   "source": [
    "question_on_wine=\"Best Italian wine that goes great with steak?\"\n",
    "recommendation = query_llm_with_rag(question_on_wine)\n",
    "print(recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5fe7f",
   "metadata": {},
   "source": [
    "You might notice that we asked for Australian wines that goes well with steak and we do not have any such wine in our collection. Therefore the model politely excuses. You may change the question and see how LLM recommends a wine from our select list that best suites your question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2adc9a2",
   "metadata": {},
   "source": [
    "### Additional info: changing kwargs for querying the LLM\n",
    "If you want to change or add new parameters for LLM querying, you're able to add in new keyword arguments to the `query_llm` function. For example, to change the `temperature` value, simply change the function call:\n",
    "`query_llm(description phrase, temperature = new float value)`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
