{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afb05169",
   "metadata": {},
   "source": [
    "# Text Chunking\n",
    "This lab will walk you through various methods to perform chunking of your text. Retrieval is a very important step in RAG architecture. Semantic search requires you take your knowledge/text and convert that into embeddings and store them in a search engine that offers vector search capability. To convert your documents into embedding, you will need to split them into smaller pieces, popularly called \"Chunks\". This technique is known as \"Chunking\". Chunking is necessary because a large text passage may reduce its specificity, it may conflate different topics or concepts making it not best match for a query about a topic. This would mean even if there is a very relevant information in one part of the text passage, the similarity of text passage as a whole to user's query may be low, this may exclude the text passage from top semantic search results.\n",
    "\n",
    "\n",
    "There is a [great resource by Greg Kamradt](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb) from where you can learn about various ways to chunk text  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218fb6d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain_community pypdf langchain_experimental --quiet\n",
    "!pip install -qU langchain-text-splitters\n",
    "!pip install --upgrade --quiet  boto3\n",
    "!pip install pdfminer.six --quiet\n",
    "!pip install amazon-textract-caller --quiet\n",
    "!pip install amazon-textract-textractor --quiet\n",
    "!pip install opensearchpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89769abf-46cd-4f8e-9d95-d323c3e491ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -qU langchain-aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1915eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sagemaker\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from sagemaker import get_execution_role\n",
    "import random \n",
    "import string\n",
    "import s3fs\n",
    "from urllib.parse import urlparse\n",
    "from IPython.display import display, HTML\n",
    "from alive_progress import alive_bar\n",
    "from opensearch_py_ml.ml_commons import MLCommonClient\n",
    "from requests_aws4auth import AWS4Auth\n",
    "import requests \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87760ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Boto3 session\n",
    "session = boto3.Session()\n",
    "\n",
    "# Get the account id\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "# Get the current region\n",
    "region = session.region_name\n",
    "\n",
    "cfn = boto3.client('cloudformation')\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "\n",
    "# Method to obtain output variables from Cloudformation stack. \n",
    "def get_cfn_outputs(stackname):\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs\n",
    "\n",
    "## Setup variables to for the rest of the demo\n",
    "cloudformation_stack_name = \"genai-data-foundation-workshop\"\n",
    "\n",
    "outputs = get_cfn_outputs(cloudformation_stack_name)\n",
    "aos_host = outputs['OpenSearchDomainEndpoint']\n",
    "s3_bucket = outputs['s3BucketTraining']\n",
    "bedrock_inf_iam_role = outputs['BedrockBatchInferenceRole']\n",
    "bedrock_inf_iam_role_arn = outputs['BedrockBatchInferenceRoleArn']\n",
    "sagemaker_notebook_url = outputs['SageMakerNotebookURL']\n",
    "\n",
    "# We will just print all the variables so you can easily copy if needed.\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3773f353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "\n",
    "def upload_file_to_s3(file_path, bucket_name, prefix):\n",
    "    s3 = boto3.client('s3')\n",
    "    file_name = os.path.basename(file_path)\n",
    "    object_key = f\"{prefix}/{file_name}\" if prefix else file_name\n",
    "    \n",
    "    with open(file_path, 'rb') as file_data:\n",
    "        s3.upload_fileobj(file_data, bucket_name, object_key)\n",
    "    \n",
    "    s3_path = f\"s3://{bucket_name}/{object_key}\"\n",
    "    return s3_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a86734",
   "metadata": {},
   "source": [
    "### Lang chain recursive character chunking\n",
    "The most simplest way to chunk document would be by length, but keeping paragraphs or lines together so it does not lose the meaning. We will use langchain library's recursive character text splitter which offers ways to split data by length, yet keeps the lines, paragraph together as much as possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a82f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this method would split the text into chunks by paragraph, line boundary and keeping chunk \n",
    "# size as close to 1000 characters, it will also overlap the text between chunks if it were to \n",
    "# split line or paragraph in the middle.\n",
    "\n",
    "def recursive_character_chunking(text): \n",
    "    \n",
    "#     embeddings = BedrockEmbeddings() #create a Titan Embeddings client\n",
    "    \n",
    "#     pdf_path = \"Amazon-com-Inc-2023-Annual-Report.pdf\" #assumes local PDF file with this name\n",
    "\n",
    "#     loader = PyPDFLoader(file_path=pdf_path) #load the pdf file\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter( #create a text splitter\n",
    "        #separators=[\"\\n\\n\", \"\\n\", \".\", \" \"], #split chunks at (1) paragraph, (2) line, (3) sentence, or (4) word, in that order\n",
    "        chunk_size=1000, #divide into 1000-character chunks using the separators above\n",
    "        chunk_overlap=100, #number of characters that can overlap with previous chunk\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    \n",
    "    docs = text_splitter.create_documents(text)#From the loaded PDF\n",
    "    \n",
    "    return docs #return the index to be cached by the client app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b894d",
   "metadata": {},
   "source": [
    "Let's try to run this method on an excerpt of AWS docs from Amazon Bedrock titan model and Amazon Textract services. You will notice that length/recursive chunking will create chunks with overlaps, this helps in situations where sentences need to not be chopped in the middle, but it will fail to keep Textract and Titan documentation chunks separate. You will notice that chunk no. 9 is a mix of titan and lambda docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237acdf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "\n",
    "#lets load text from our prepared aws-docs-excerpt from various services.\n",
    "with open('aws-docs-excerpt.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "\n",
    "docs = recursive_character_chunking([text])\n",
    "\n",
    "# the method prints chunks\n",
    "def print_chunks(data):\n",
    "    #Let's print the chunks -- notice the overlap between chunk 3 and 4\n",
    "    i = 1\n",
    "    for doc in data:\n",
    "        print(f\"---------START OF CHUNK {i}------\")\n",
    "        print(f\"{doc.page_content}\")\n",
    "        print(f\"---------END OF CHUNK {i}------\\n\\n\")\n",
    "        i+=1\n",
    "        \n",
    "print_chunks(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6519d5f2-9c1d-4a9e-8d44-ee0b1e060486",
   "metadata": {},
   "source": [
    "## PDF Parsing\n",
    "We have to convert our files into a String object before we can perform any form of chunking strategy. Here, we will parse our PDF into a string using PyPDFLoader from Langchain. This library will attempt to retain the format of the texts as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad33dfd3-1728-491c-9c2c-db189d3b5b5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"Amazon-com-Inc-2023-Annual-Report.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "#print(documents)\n",
    "\n",
    "texts = \"\"\n",
    "\n",
    "for document in documents:\n",
    "    texts += document.page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3cc9d",
   "metadata": {},
   "source": [
    "### Semantic chunking\n",
    "Semantic chunking is a novel technique that chunks the data in a way that it optimises it for semantic cohesion. The method uses an embedding model and runs similarity calculation over sentences and decides the chunk position based on deviation/change in semantic distance between sentences. It uses rolling window where it keeps adding sentences and measure its distance with incoming sentence. Technically a change in topic should be detected (not very accurately). A breakpoint threshold is statistical method use to determine this change. This way you ensure that chunks stay optimal for semantic matching. \n",
    "\n",
    "If you are keen to get more info, read level 4 in [Greg Kamradt tutorial](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb).\n",
    "\n",
    "Langchain offers semantic chunking and also ability to call embedding model. We will first choose an embedding model for our semantic chunking a a breakpoint threshold type. After selecting the model and threshold, please move to the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67023018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lets initialize the code for drop down box input.\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive\n",
    "\n",
    "#defaults\n",
    "model_id='amazon.titan-embed-text-v2:0'\n",
    "threshold = 'percentile'\n",
    "\n",
    "#list of embedding models in bedrock\n",
    "model_list=['cohere.embed-english-v3','cohere.embed-multilingual-v3',\n",
    "            'amazon.titan-embed-text-v1','amazon.titan-embed-text-v2:0',\n",
    "           'amazon.titan-embed-image-v1']\n",
    "\n",
    "#semantic chunking \n",
    "threshold_list=['percentile', 'standard_deviation', 'interquartile']\n",
    "    \n",
    "drop1 = widgets.Dropdown(options=model_list, value='cohere.embed-english-v3', description='Model:', disabled=False)\n",
    "drop2 = widgets.Dropdown(options=threshold_list, value='percentile', description='Threshold:', disabled=False)\n",
    "\n",
    "def get_model_dimension(model_id):\n",
    "    if model_id==\"amazon.titan-embed-text-v2:0\":\n",
    "        return 1024\n",
    "    if model_id.startswith(\"cohere\"):\n",
    "        return 512\n",
    "    if model_id.startswith(\"amazon.titan-embed-text-v1\"):\n",
    "        return 8192\n",
    "    if model_id.startswith(\"amazon.titan-embed-image-v1\"):\n",
    "        return 8192"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a066d49",
   "metadata": {},
   "source": [
    "Following code runs semantic chunking for aws docs text. It also shows a drop down for you to change the model and threshold type so you can see the effects of various models and breakpoint thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64ea9c0a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d121622abb14523be5b29fbe089ae1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Model:', options=('cohere.embed-english-v3', 'cohere.embed-multiliâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "#from langchain_community.embeddings import BedrockEmbedding\n",
    "from langchain_community.document_loaders import PDFMinerLoader\n",
    "\n",
    "#method that is called when drop down boxes are shown or changed\n",
    "def update_dropdown(selected_model, selected_threshold):\n",
    "    model_id = selected_model.lower()\n",
    "    threshold = selected_threshold.lower()\n",
    "    info = f\"Selected embedding model: {model_id}. Selected threshold: {threshold}!\"\n",
    "    display(info)\n",
    "    semantic_chunks = perform_semantic_chunking(text=text, model_id=model_id, threshold=threshold)\n",
    "    print_chunks(semantic_chunks)\n",
    "\n",
    "    \n",
    "# method runs semantic chunking on text for a given model and threshold.    \n",
    "def perform_semantic_chunking(text, model_id, threshold):\n",
    "    print(f\"Chunking using {model_id} and {threshold} threshold breaking point\")\n",
    "    \n",
    "    #using lang chain's Bedrock embedding object\n",
    "    embeddings = BedrockEmbeddings(region_name=region, model_id=model_id)\n",
    "\n",
    "    #using lang chain's semantic chunker to chunk\n",
    "    text_splitter = SemanticChunker(\n",
    "        embeddings, breakpoint_threshold_type= threshold\n",
    "    )\n",
    "\n",
    "    docs = text_splitter.create_documents([text])\n",
    "    return docs\n",
    "\n",
    "#lets run semantic chunking and display the drop down. \n",
    "w = interactive(update_dropdown, selected_model=drop1, selected_threshold=drop2) \n",
    "display(w)\n",
    "\n",
    "#when you change value - give it takes a 10-15 seconds for refreshing the chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ae5ea4",
   "metadata": {},
   "source": [
    "You can run above cell a number of with different combination of the embedding model and threshold ids to see what breaks the content best. You will find results vary from one model to another and between various breakpoint threshold technique. However, it does not mean this combination will always be best for chunking. Note that this also does not mean it is optimal for retrieval. We will have to test this with our queries to know if this is best to answer our questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a0e8a",
   "metadata": {},
   "source": [
    "### Loading text chunks in opensearch to run semantic search over chunks\n",
    "\n",
    "#### Let's first create an index with KNN field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f2f5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_index = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True,\n",
    "        \"index.knn.space_type\": \"cosinesimil\",\n",
    "        \"analysis\": {\n",
    "          \"analyzer\": {\n",
    "            \"default\": {\n",
    "              \"type\": \"standard\",\n",
    "              \"stopwords\": \"_english_\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"chunk_vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": get_model_dimension(model_id=model_id),\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"chunk_content\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c1c54",
   "metadata": {},
   "source": [
    "### Connect to Amazon OpenSearch Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f2d3ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kms = boto3.client('secretsmanager')\n",
    "aos_credentials = json.loads(kms.get_secret_value(SecretId=outputs['DBSecret'])['SecretString'])\n",
    "\n",
    "# For this lab we will use credentials that we have already created in AWS Secrets manager service. Secrets\n",
    "# manager service allows you to store secrets securily and retrieve it through code in a safe manner.\n",
    "\n",
    "auth = (aos_credentials['username'], aos_credentials['password'])\n",
    "\n",
    "aos_client = OpenSearch(\n",
    "    hosts = [{'host': aos_host, 'port': 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5424188e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'aws_docs_index' not found. Creating index on cluster.\n"
     ]
    }
   ],
   "source": [
    "index_name = \"aws_docs_index\"\n",
    "\n",
    "try:\n",
    "    aos_client.indices.delete(index=index_name)\n",
    "    print(\"Recreating index '\" + index_name + \"' on cluster.\")\n",
    "    aos_client.indices.create(index=index_name,body=knn_index,ignore=400)\n",
    "except:\n",
    "    print(\"Index '\" + index_name + \"' not found. Creating index on cluster.\")\n",
    "    aos_client.indices.create(index=index_name,body=knn_index,ignore=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c4b3b60",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.093402214,\n",
       " 0.014612454,\n",
       " -0.0038183297,\n",
       " -0.003836687,\n",
       " -0.021881966,\n",
       " -0.0019367008,\n",
       " 0.06373673,\n",
       " -0.06961109,\n",
       " 0.006425074,\n",
       " -0.03392439,\n",
       " 0.011087841,\n",
       " -0.10103887,\n",
       " 0.04523252,\n",
       " -0.023937989,\n",
       " -0.020560237,\n",
       " -0.010867554,\n",
       " -0.042001627,\n",
       " -0.0031391075,\n",
       " 0.05257546,\n",
       " 0.02893119,\n",
       " -0.0044791945,\n",
       " 0.04023932,\n",
       " 0.024231708,\n",
       " 0.04023932,\n",
       " 0.041707907,\n",
       " -0.012923577,\n",
       " -0.06961109,\n",
       " -0.06373673,\n",
       " 0.022175683,\n",
       " -0.034071248,\n",
       " 0.007453086,\n",
       " -0.012262712,\n",
       " -0.017916778,\n",
       " -0.014465595,\n",
       " 0.04523252,\n",
       " -0.022909978,\n",
       " 0.10103887,\n",
       " 0.035833556,\n",
       " -0.043176495,\n",
       " 0.021588247,\n",
       " 0.050519437,\n",
       " 0.011601848,\n",
       " -0.0024598853,\n",
       " -0.02760946,\n",
       " 0.0049564857,\n",
       " -0.033336956,\n",
       " 0.0065719327,\n",
       " 0.01879793,\n",
       " -0.021000814,\n",
       " 0.06344301,\n",
       " 0.039651886,\n",
       " -0.02628773,\n",
       " -0.0061680707,\n",
       " 0.14979601,\n",
       " 0.02129453,\n",
       " -0.004203834,\n",
       " 0.021881966,\n",
       " 0.016081043,\n",
       " 0.069023654,\n",
       " 0.029371766,\n",
       " -0.0010968519,\n",
       " -0.030399779,\n",
       " -0.06608647,\n",
       " 0.025847154,\n",
       " -0.009215391,\n",
       " -0.06373673,\n",
       " 0.0014043376,\n",
       " 0.018137066,\n",
       " -0.033630673,\n",
       " -0.029371766,\n",
       " -0.044938803,\n",
       " -0.009692683,\n",
       " 0.027462602,\n",
       " -0.061974425,\n",
       " -0.038477015,\n",
       " 0.0044791945,\n",
       " -0.023056837,\n",
       " 0.010206689,\n",
       " -0.015199889,\n",
       " -0.019972801,\n",
       " -0.01879793,\n",
       " -0.020560237,\n",
       " 0.036861565,\n",
       " -0.032896377,\n",
       " -0.014685883,\n",
       " -0.008260809,\n",
       " -0.021588247,\n",
       " -0.025259718,\n",
       " 0.040826757,\n",
       " 0.015860753,\n",
       " 0.046701107,\n",
       " 0.028637473,\n",
       " 0.02760946,\n",
       " 0.016154472,\n",
       " 0.06961109,\n",
       " -0.064911604,\n",
       " -0.009472394,\n",
       " 0.050813157,\n",
       " -0.05022572,\n",
       " 0.023644272,\n",
       " 0.084003255,\n",
       " 0.032162085,\n",
       " -0.0015511964,\n",
       " -0.007049224,\n",
       " 0.029371766,\n",
       " -0.009839541,\n",
       " 0.04758226,\n",
       " 0.04905085,\n",
       " 0.030693496,\n",
       " 0.017035624,\n",
       " 0.02643459,\n",
       " 0.02628773,\n",
       " -0.03877073,\n",
       " -0.0007342942,\n",
       " 0.038477015,\n",
       " -0.01505303,\n",
       " 0.06608647,\n",
       " 0.0040569752,\n",
       " -0.026581448,\n",
       " 0.044938803,\n",
       " -0.037449002,\n",
       " -0.024084847,\n",
       " -0.047288544,\n",
       " 0.03509926,\n",
       " -0.031574648,\n",
       " -0.045819957,\n",
       " -0.022175683,\n",
       " -0.038183294,\n",
       " 0.02760946,\n",
       " 0.042295344,\n",
       " -0.0011197986,\n",
       " 0.028050037,\n",
       " -0.07695403,\n",
       " 0.013437583,\n",
       " 0.0046444107,\n",
       " 0.020707095,\n",
       " 0.0038183297,\n",
       " 0.010206689,\n",
       " 0.047288544,\n",
       " -0.0017255913,\n",
       " -0.016227901,\n",
       " -0.021000814,\n",
       " 0.03877073,\n",
       " -0.049344566,\n",
       " 0.023203695,\n",
       " -0.00048876455,\n",
       " 0.013511012,\n",
       " 0.025700295,\n",
       " -0.050519437,\n",
       " -0.045526236,\n",
       " -0.025994014,\n",
       " 0.015787324,\n",
       " -0.045526236,\n",
       " -0.08517812,\n",
       " 0.0024048134,\n",
       " -0.034658685,\n",
       " -0.07196083,\n",
       " 0.034658685,\n",
       " -0.04376393,\n",
       " -0.033336956,\n",
       " 0.019238507,\n",
       " 0.001477767,\n",
       " -0.06461789,\n",
       " -0.009619254,\n",
       " 0.0006654541,\n",
       " 0.04141419,\n",
       " 0.020266518,\n",
       " 0.021441389,\n",
       " -0.019972801,\n",
       " 0.047288544,\n",
       " -0.03509926,\n",
       " -0.025406579,\n",
       " 0.064911604,\n",
       " -0.0013125509,\n",
       " -0.0119689945,\n",
       " 0.0019550582,\n",
       " 0.008334239,\n",
       " 0.018724501,\n",
       " -0.046994828,\n",
       " -0.007379656,\n",
       " -0.033483814,\n",
       " 0.012262712,\n",
       " -0.0017990207,\n",
       " -0.02129453,\n",
       " -0.024084847,\n",
       " 0.008554527,\n",
       " -0.010867554,\n",
       " -0.009472394,\n",
       " 0.018137066,\n",
       " -0.012483001,\n",
       " -0.06344301,\n",
       " 0.0069390796,\n",
       " 0.024672283,\n",
       " -0.010500407,\n",
       " 0.023350554,\n",
       " 0.07254826,\n",
       " 0.022175683,\n",
       " 0.022175683,\n",
       " 0.024525424,\n",
       " -0.030399779,\n",
       " 0.046113674,\n",
       " -0.004736197,\n",
       " 0.045526236,\n",
       " 0.03509926,\n",
       " 0.009215391,\n",
       " 0.018724501,\n",
       " 0.042295344,\n",
       " -0.012262712,\n",
       " -0.04905085,\n",
       " -0.023056837,\n",
       " 0.019238507,\n",
       " -0.06667391,\n",
       " -0.06138699,\n",
       " 0.03656785,\n",
       " 0.007930377,\n",
       " -0.042001627,\n",
       " 0.0010050652,\n",
       " 0.035833556,\n",
       " 0.014612454,\n",
       " -0.03906445,\n",
       " -0.013290724,\n",
       " 0.0027719603,\n",
       " -0.023203695,\n",
       " 0.022469401,\n",
       " -0.03642099,\n",
       " -0.040533036,\n",
       " -0.03642099,\n",
       " -0.0051033446,\n",
       " 0.0006654541,\n",
       " 0.032308944,\n",
       " -0.0022763119,\n",
       " 0.013217295,\n",
       " 0.05022572,\n",
       " -0.04905085,\n",
       " -0.051988028,\n",
       " 0.0068656504,\n",
       " -0.009619254,\n",
       " 0.018504214,\n",
       " -0.008260809,\n",
       " 0.034805544,\n",
       " 0.005029915,\n",
       " -0.0031758223,\n",
       " -0.02011966,\n",
       " 0.0059844973,\n",
       " -0.046994828,\n",
       " -0.0010234225,\n",
       " -0.017843347,\n",
       " 0.0050666295,\n",
       " 0.0013676229,\n",
       " -0.055512637,\n",
       " 0.03656785,\n",
       " -0.034218106,\n",
       " 0.0028086752,\n",
       " 0.058449816,\n",
       " 0.0070125093,\n",
       " -0.0010876732,\n",
       " 0.012850148,\n",
       " 0.028050037,\n",
       " 0.01754963,\n",
       " -0.044938803,\n",
       " -0.061093275,\n",
       " -0.04758226,\n",
       " 0.021881966,\n",
       " -0.024819143,\n",
       " 0.046113674,\n",
       " 0.035833556,\n",
       " -0.0023680986,\n",
       " 0.05903725,\n",
       " -0.0052134884,\n",
       " -0.008407668,\n",
       " -0.018944789,\n",
       " 0.015346748,\n",
       " 0.023056837,\n",
       " 0.017696489,\n",
       " 0.020853953,\n",
       " 0.0046076956,\n",
       " 0.017255913,\n",
       " -0.058449816,\n",
       " 0.022028824,\n",
       " 0.021588247,\n",
       " -0.030546637,\n",
       " 0.069023654,\n",
       " 0.007893662,\n",
       " -0.018137066,\n",
       " 0.014906172,\n",
       " 0.004497552,\n",
       " -0.015934182,\n",
       " -0.014685883,\n",
       " -0.009068533,\n",
       " -0.0043323357,\n",
       " 0.012115854,\n",
       " 0.004809627,\n",
       " -0.017843347,\n",
       " 0.018137066,\n",
       " 0.035686694,\n",
       " -0.011234701,\n",
       " 0.007967091,\n",
       " 0.03759586,\n",
       " -0.025700295,\n",
       " 0.01505303,\n",
       " 0.019532224,\n",
       " 0.017402772,\n",
       " -0.03627413,\n",
       " 0.06843621,\n",
       " 0.0026801736,\n",
       " -0.043176495,\n",
       " 0.040533036,\n",
       " -0.025259718,\n",
       " 0.040826757,\n",
       " 0.00881153,\n",
       " -0.0006929901,\n",
       " 0.015346748,\n",
       " 0.010940983,\n",
       " -0.0049564857,\n",
       " 0.031134073,\n",
       " 0.018724501,\n",
       " 0.05786238,\n",
       " -0.01505303,\n",
       " -0.016081043,\n",
       " 0.016962195,\n",
       " 0.021147672,\n",
       " 0.003946831,\n",
       " -0.008040521,\n",
       " -0.044645086,\n",
       " -0.00016636352,\n",
       " 0.067261346,\n",
       " -0.039651886,\n",
       " -0.009215391,\n",
       " -0.06549904,\n",
       " 0.05521892,\n",
       " 0.0016888765,\n",
       " -0.0067187916,\n",
       " 0.0075999447,\n",
       " -0.014759312,\n",
       " 0.009912971,\n",
       " -0.023056837,\n",
       " 0.059624687,\n",
       " 0.03128093,\n",
       " -0.004405765,\n",
       " -0.0012574787,\n",
       " 0.025847154,\n",
       " 0.028050037,\n",
       " -0.024525424,\n",
       " -0.010940983,\n",
       " -0.013878159,\n",
       " 0.027462602,\n",
       " 0.037008427,\n",
       " 0.009288821,\n",
       " 0.0025883869,\n",
       " 0.0036714708,\n",
       " -0.0033593958,\n",
       " -0.001762306,\n",
       " 0.007159368,\n",
       " 0.067261346,\n",
       " -0.030987212,\n",
       " 0.024672283,\n",
       " -0.025700295,\n",
       " 0.018283924,\n",
       " 0.006204786,\n",
       " -0.007746803,\n",
       " 0.023056837,\n",
       " -0.024966002,\n",
       " -0.010133259,\n",
       " -0.01754963,\n",
       " -0.0073429416,\n",
       " -0.0007664195,\n",
       " -0.003322681,\n",
       " 0.010794124,\n",
       " -0.039945602,\n",
       " -0.044938803,\n",
       " -0.034511827,\n",
       " 0.006204786,\n",
       " -0.039651886,\n",
       " -0.046113674,\n",
       " 0.0029188192,\n",
       " 0.009912971,\n",
       " 0.04376393,\n",
       " 0.027022025,\n",
       " 0.022469401,\n",
       " -0.024084847,\n",
       " 0.011895565,\n",
       " 0.042295344,\n",
       " 0.014098448,\n",
       " -0.014979601,\n",
       " -0.011454989,\n",
       " 0.037155285,\n",
       " -0.0036163987,\n",
       " 0.015934182,\n",
       " -0.0031391075,\n",
       " -0.009362251,\n",
       " 0.015787324,\n",
       " -0.00025585562,\n",
       " 0.015493606,\n",
       " 0.064911604,\n",
       " -0.002441528,\n",
       " -0.009766112,\n",
       " 0.05404405,\n",
       " 0.034658685,\n",
       " 0.038477015,\n",
       " -0.06961109,\n",
       " 0.005654065,\n",
       " 0.03274952,\n",
       " 0.06843621,\n",
       " 0.025847154,\n",
       " 0.075779155,\n",
       " 0.044938803,\n",
       " 0.007049224,\n",
       " 0.034658685,\n",
       " -0.031868365,\n",
       " -0.008481097,\n",
       " 0.009288821,\n",
       " -0.028637473,\n",
       " 0.021588247,\n",
       " 0.0002053729,\n",
       " 0.033043236,\n",
       " 0.006902365,\n",
       " -0.015346748,\n",
       " -0.0049932003,\n",
       " 0.012997007,\n",
       " 0.017990207,\n",
       " 0.01879793,\n",
       " 0.013878159,\n",
       " -0.028196895,\n",
       " -0.008554527,\n",
       " 0.07019852,\n",
       " -0.01754963,\n",
       " 0.0022854905,\n",
       " -0.025994014,\n",
       " -0.01754963,\n",
       " 0.03392439,\n",
       " 0.009839541,\n",
       " 0.0017714846,\n",
       " 0.005397062,\n",
       " 0.030987212,\n",
       " -0.006645362,\n",
       " 0.0049197706,\n",
       " 0.02628773,\n",
       " -0.015273319,\n",
       " -0.0143921655,\n",
       " 0.012997007,\n",
       " 0.004038618,\n",
       " 0.023644272,\n",
       " -0.009619254,\n",
       " -0.016154472,\n",
       " -0.035980415,\n",
       " -0.013878159,\n",
       " -0.029518625,\n",
       " 0.015199889,\n",
       " 0.074898005,\n",
       " -0.014171877,\n",
       " -0.03392439,\n",
       " -0.061974425,\n",
       " -0.008627957,\n",
       " -0.011087841,\n",
       " 0.0016980552,\n",
       " -0.017255913,\n",
       " 0.01754963,\n",
       " 0.016081043,\n",
       " -0.01879793,\n",
       " 0.009692683,\n",
       " 0.010794124,\n",
       " -0.053750332,\n",
       " -0.06843621,\n",
       " 0.034218106,\n",
       " -0.025994014,\n",
       " 0.0016429832,\n",
       " -0.06784878,\n",
       " 0.007159368,\n",
       " 0.031574648,\n",
       " -0.06461789,\n",
       " 0.0076366593,\n",
       " -0.07754146,\n",
       " -0.045526236,\n",
       " 0.014465595,\n",
       " 0.028637473,\n",
       " -0.004772912,\n",
       " 0.008554527,\n",
       " -0.0037449002,\n",
       " -0.003689828,\n",
       " -0.048463415,\n",
       " 0.015860753,\n",
       " 0.062268145,\n",
       " 0.009839541,\n",
       " -0.038183294,\n",
       " -0.003891759,\n",
       " -0.024378566,\n",
       " 0.025994014,\n",
       " -0.0051767738,\n",
       " -0.008260809,\n",
       " 5.650623e-05,\n",
       " -0.014685883,\n",
       " 0.02628773,\n",
       " -0.014318736,\n",
       " -0.0015787324,\n",
       " -0.012409572,\n",
       " -0.0021937038,\n",
       " 0.043176495,\n",
       " -0.024819143,\n",
       " -0.021735108,\n",
       " -0.034658685,\n",
       " 0.032162085,\n",
       " 0.0067922208,\n",
       " 0.012483001,\n",
       " 0.02893119,\n",
       " -0.0038183297,\n",
       " -0.02643459,\n",
       " 0.0009132784,\n",
       " -0.022763118,\n",
       " 0.051694307,\n",
       " 0.025847154,\n",
       " 0.010647265,\n",
       " 0.0006195607,\n",
       " 0.032455802,\n",
       " -0.020853953,\n",
       " -0.027462602,\n",
       " 0.04023932,\n",
       " 0.011528418,\n",
       " -0.035392977,\n",
       " 0.037155285,\n",
       " 0.037889577,\n",
       " -0.008701386,\n",
       " -0.01505303,\n",
       " -0.006131356,\n",
       " -0.00046811253,\n",
       " -0.027756318,\n",
       " -0.008664671,\n",
       " 0.043176495,\n",
       " 0.0014135162,\n",
       " 0.011234701,\n",
       " 0.027756318,\n",
       " -0.0014594096,\n",
       " 0.00022028825,\n",
       " 0.011234701,\n",
       " -0.009766112,\n",
       " -0.015493606,\n",
       " 0.022175683,\n",
       " -0.022763118,\n",
       " 0.016521618,\n",
       " -0.038477015,\n",
       " 0.030693496,\n",
       " 0.035833556,\n",
       " -0.07049224,\n",
       " -0.033630673,\n",
       " 0.05286918,\n",
       " -0.010867554,\n",
       " 0.022469401,\n",
       " -0.07137339,\n",
       " 0.013878159,\n",
       " -0.041707907,\n",
       " 0.059624687,\n",
       " 0.059918404,\n",
       " -0.021147672,\n",
       " 0.043176495,\n",
       " 0.02643459,\n",
       " -0.03906445,\n",
       " 0.019972801,\n",
       " -0.009619254,\n",
       " 0.003102393,\n",
       " 0.028637473,\n",
       " 0.053750332,\n",
       " 0.035686694,\n",
       " 0.012997007,\n",
       " -0.0055439207,\n",
       " -0.017255913,\n",
       " -0.019091647,\n",
       " -0.054337766,\n",
       " -0.016815336,\n",
       " -0.0143921655,\n",
       " 0.009766112,\n",
       " 0.014171877,\n",
       " 0.012262712,\n",
       " 0.033043236,\n",
       " 0.039651886,\n",
       " 0.040826757,\n",
       " -0.0023038478,\n",
       " 0.0119689945,\n",
       " 0.03010606,\n",
       " -0.011822136,\n",
       " 0.044938803,\n",
       " 0.01130813,\n",
       " -0.0029188192,\n",
       " -0.007379656,\n",
       " 0.012923577,\n",
       " 0.025406579,\n",
       " -0.021881966,\n",
       " -0.049344566,\n",
       " -0.030987212,\n",
       " -0.0070125093,\n",
       " 0.02893119,\n",
       " -0.016962195,\n",
       " -0.051988028,\n",
       " 0.012042424,\n",
       " -0.01005983,\n",
       " 0.015199889,\n",
       " 0.041707907,\n",
       " 0.049932003,\n",
       " 0.0046994826,\n",
       " -0.022028824,\n",
       " 0.028343754,\n",
       " 0.033483814,\n",
       " -0.008224094,\n",
       " -0.019385366,\n",
       " 0.007893662,\n",
       " -0.037889577,\n",
       " -0.04023932,\n",
       " 0.03906445,\n",
       " 0.0049564857,\n",
       " -0.012923577,\n",
       " 0.10045144,\n",
       " -0.07372313,\n",
       " 0.064911604,\n",
       " 7.027425e-05,\n",
       " -0.039651886,\n",
       " -0.0027719603,\n",
       " 0.030693496,\n",
       " 0.0070125093,\n",
       " 0.0005140059,\n",
       " 0.02129453,\n",
       " 0.033043236,\n",
       " 0.061974425,\n",
       " -0.03906445,\n",
       " 0.021735108,\n",
       " 0.006057927,\n",
       " -0.009766112,\n",
       " -0.035686694,\n",
       " -0.06931737,\n",
       " -0.012336141,\n",
       " -0.019385366,\n",
       " 0.018137066,\n",
       " -0.021000814,\n",
       " 0.013437583,\n",
       " 0.019825943,\n",
       " -0.0030473208,\n",
       " 0.022322543,\n",
       " 0.004736197,\n",
       " -0.0061680707,\n",
       " 0.05786238,\n",
       " 0.06961109,\n",
       " 0.027462602,\n",
       " -0.01637476,\n",
       " 0.05404405,\n",
       " -0.06021212,\n",
       " 0.0067187916,\n",
       " -0.047875978,\n",
       " -0.013511012,\n",
       " -0.010426977,\n",
       " 0.001505303,\n",
       " -0.022469401,\n",
       " -0.034071248,\n",
       " -0.0070125093,\n",
       " -0.014465595,\n",
       " 0.002698531,\n",
       " 0.032308944,\n",
       " 0.019972801,\n",
       " 0.014318736,\n",
       " -0.00015030084,\n",
       " -0.023350554,\n",
       " 0.00068381144,\n",
       " 0.009362251,\n",
       " 0.014906172,\n",
       " -0.018724501,\n",
       " -0.027168883,\n",
       " 0.02628773,\n",
       " 0.0049564857,\n",
       " -0.003377753,\n",
       " 0.053162895,\n",
       " 0.00060120336,\n",
       " -0.0075999447,\n",
       " -0.016815336,\n",
       " 0.0029188192,\n",
       " 0.04905085,\n",
       " -0.08106607,\n",
       " -0.022469401,\n",
       " 0.031574648,\n",
       " 0.031134073,\n",
       " 0.001762306,\n",
       " 0.011234701,\n",
       " -0.028343754,\n",
       " 0.004497552,\n",
       " 0.019825943,\n",
       " -0.032162085,\n",
       " -0.004203834,\n",
       " 0.0042405487,\n",
       " 0.019532224,\n",
       " 0.024231708,\n",
       " 0.03524612,\n",
       " -0.03524612,\n",
       " 0.04640739,\n",
       " -0.004185477,\n",
       " -0.028784331,\n",
       " -0.013217295,\n",
       " 0.050813157,\n",
       " 0.048463415,\n",
       " -0.020707095,\n",
       " 0.050813157,\n",
       " -0.044938803,\n",
       " -0.027022025,\n",
       " 0.012409572,\n",
       " 0.020560237,\n",
       " 0.031134073,\n",
       " 0.01255643,\n",
       " 0.012409572,\n",
       " -0.008848244,\n",
       " -0.0005140059,\n",
       " 0.0119689945,\n",
       " 0.017696489,\n",
       " -0.028784331,\n",
       " -0.0070859385,\n",
       " 0.0069390796,\n",
       " -0.0032308942,\n",
       " -0.023497414,\n",
       " -0.04258906,\n",
       " -0.009362251,\n",
       " 0.0010234225,\n",
       " 0.007746803,\n",
       " -0.013437583,\n",
       " 0.057568662,\n",
       " 0.022909978,\n",
       " -0.0067187916,\n",
       " -0.017329343,\n",
       " -0.0026618163,\n",
       " 0.04376393,\n",
       " -0.059624687,\n",
       " -0.005911068,\n",
       " 0.041707907,\n",
       " -0.0029188192,\n",
       " 0.012042424,\n",
       " 0.011675277,\n",
       " 0.057568662,\n",
       " 0.021735108,\n",
       " 0.039945602,\n",
       " -0.03642099,\n",
       " 0.00030978036,\n",
       " -0.005800924,\n",
       " 0.015493606,\n",
       " -0.025700295,\n",
       " -0.0019458795,\n",
       " 0.012850148,\n",
       " -0.032896377,\n",
       " 0.004112047,\n",
       " -0.029224908,\n",
       " 0.006204786,\n",
       " 0.0008857423,\n",
       " 0.023056837,\n",
       " -0.08282838,\n",
       " 0.037155285,\n",
       " -0.053162895,\n",
       " -0.0010142438,\n",
       " 0.0020101303,\n",
       " 0.020853953,\n",
       " 0.03010606,\n",
       " -0.016962195,\n",
       " 0.027168883,\n",
       " 0.015934182,\n",
       " -0.0051767738,\n",
       " -0.03906445,\n",
       " -0.005800924,\n",
       " 0.018137066,\n",
       " 0.0035062546,\n",
       " 0.0011014412,\n",
       " -0.019825943,\n",
       " 0.025847154,\n",
       " -0.007783518,\n",
       " -0.011675277,\n",
       " -0.016741907,\n",
       " -0.008627957,\n",
       " 0.017990207,\n",
       " -0.00054842595,\n",
       " -0.027462602,\n",
       " -0.002441528,\n",
       " -0.05521892,\n",
       " 0.021735108,\n",
       " -0.006278215,\n",
       " -0.012189283,\n",
       " -0.009252107,\n",
       " 0.0010142438,\n",
       " -0.019825943,\n",
       " -0.0025149575,\n",
       " 0.040826757,\n",
       " 0.038183294,\n",
       " 0.01762306,\n",
       " -0.038477015,\n",
       " -0.026875166,\n",
       " -0.024525424,\n",
       " -0.07871633,\n",
       " 0.024084847,\n",
       " 0.008958389,\n",
       " 0.07137339,\n",
       " -0.021881966,\n",
       " 0.003377753,\n",
       " -0.02011966,\n",
       " -0.07431057,\n",
       " -0.0037632575,\n",
       " 0.02511286,\n",
       " -0.0056907795,\n",
       " 0.028050037,\n",
       " 0.021881966,\n",
       " 0.028050037,\n",
       " 0.008260809,\n",
       " 0.0072327973,\n",
       " 0.016081043,\n",
       " -0.0089216735,\n",
       " -0.016668478,\n",
       " -0.011528418,\n",
       " -0.041707907,\n",
       " -0.02643459,\n",
       " 0.0070859385,\n",
       " 0.037449002,\n",
       " -0.062268145,\n",
       " 0.0011335666,\n",
       " -0.02511286,\n",
       " 0.016962195,\n",
       " -0.002248776,\n",
       " 0.004772912,\n",
       " 0.039358165,\n",
       " -0.007820233,\n",
       " -0.016962195,\n",
       " -0.014979601,\n",
       " 0.010206689,\n",
       " -0.021881966,\n",
       " 0.025406579,\n",
       " 0.00033961106,\n",
       " 0.003891759,\n",
       " 0.017255913,\n",
       " -0.0036531135,\n",
       " 0.04523252,\n",
       " 0.012703289,\n",
       " -0.014685883,\n",
       " -0.026875166,\n",
       " 0.021000814,\n",
       " 0.010500407,\n",
       " -0.006755506,\n",
       " 0.016227901,\n",
       " -0.037449002,\n",
       " -0.02893119,\n",
       " -0.05286918,\n",
       " -0.07519172,\n",
       " 0.046701107,\n",
       " -0.003891759,\n",
       " -0.023937989,\n",
       " 0.0019550582,\n",
       " -0.05786238,\n",
       " 0.018283924,\n",
       " -0.0036714708,\n",
       " 0.016448189,\n",
       " 0.025847154,\n",
       " -0.019238507,\n",
       " -0.050813157,\n",
       " -0.031574648,\n",
       " -0.026875166,\n",
       " 0.025406579,\n",
       " -0.07930377,\n",
       " -0.044351365,\n",
       " 0.084003255,\n",
       " -0.0014594096,\n",
       " 0.039358165,\n",
       " -0.030693496,\n",
       " -0.021735108,\n",
       " 0.0049564857,\n",
       " 0.014171877,\n",
       " -0.021735108,\n",
       " 0.0038183297,\n",
       " 0.015273319,\n",
       " 0.027462602,\n",
       " 0.055512637,\n",
       " 0.0022854905,\n",
       " 0.027756318,\n",
       " -0.034218106,\n",
       " -0.016962195,\n",
       " 0.0024048134,\n",
       " -0.0016796979,\n",
       " -0.050519437,\n",
       " 0.028343754,\n",
       " 0.025847154,\n",
       " -0.0076366593,\n",
       " -0.013878159,\n",
       " 0.023644272,\n",
       " 0.016815336,\n",
       " 0.040826757,\n",
       " 0.058743533,\n",
       " -0.038477015,\n",
       " 0.043176495,\n",
       " -0.012850148,\n",
       " 0.031868365,\n",
       " -0.056100074,\n",
       " -0.023350554,\n",
       " 0.02011966,\n",
       " -0.0058743535,\n",
       " 0.010133259,\n",
       " 0.020266518,\n",
       " -0.0017990207,\n",
       " -0.044645086,\n",
       " 0.011528418,\n",
       " -2.7392614e-05,\n",
       " 0.022469401,\n",
       " 0.0025883869,\n",
       " -0.09105247,\n",
       " 0.0039835456,\n",
       " -0.028343754,\n",
       " -0.027022025,\n",
       " -0.04141419,\n",
       " 0.019532224,\n",
       " -0.074016854,\n",
       " -0.027462602,\n",
       " 0.0051767738,\n",
       " 0.019972801,\n",
       " 0.01380473,\n",
       " -0.024525424,\n",
       " -0.044351365,\n",
       " -0.0005438366,\n",
       " 0.015493606,\n",
       " -0.02129453,\n",
       " -0.014098448,\n",
       " 0.0066086473,\n",
       " -0.011601848,\n",
       " -0.007783518,\n",
       " -0.00881153,\n",
       " 0.016154472,\n",
       " 0.005029915,\n",
       " -0.04405765,\n",
       " -0.049638286,\n",
       " 0.017329343,\n",
       " 0.004736197,\n",
       " 0.056687508,\n",
       " -0.0012024067,\n",
       " -0.008481097,\n",
       " 0.027168883,\n",
       " -0.0057274946,\n",
       " -0.024378566,\n",
       " -0.008517812,\n",
       " 0.024378566,\n",
       " 0.03509926,\n",
       " -0.0143921655,\n",
       " 0.03524612,\n",
       " 0.039358165,\n",
       " -0.013217295,\n",
       " 0.028784331,\n",
       " 0.009398965,\n",
       " 0.000562194,\n",
       " 0.070785955,\n",
       " 0.028784331,\n",
       " 0.0044608368,\n",
       " -0.049932003,\n",
       " 0.021588247,\n",
       " 0.019972801,\n",
       " -0.0007664195,\n",
       " 0.013437583,\n",
       " -0.013878159,\n",
       " -0.04258906,\n",
       " -0.024525424,\n",
       " 0.02129453,\n",
       " 0.05903725,\n",
       " 0.03877073,\n",
       " 0.031134073,\n",
       " 0.019238507,\n",
       " -0.023350554,\n",
       " 0.0025883869,\n",
       " -0.010720694,\n",
       " 0.014612454,\n",
       " -0.039945602,\n",
       " 0.010940983,\n",
       " 0.016227901,\n",
       " -0.022175683,\n",
       " 0.025847154,\n",
       " 0.009398965,\n",
       " -0.039945602,\n",
       " -0.010720694,\n",
       " 0.055512637,\n",
       " -0.034658685,\n",
       " 0.028343754,\n",
       " 0.03010606,\n",
       " 0.01754963,\n",
       " 0.033336956,\n",
       " 0.031574648,\n",
       " 0.0013768015,\n",
       " 0.0027352457,\n",
       " -0.016081043,\n",
       " -0.012703289,\n",
       " 0.031721506,\n",
       " -0.021881966,\n",
       " -0.025847154,\n",
       " 0.012923577,\n",
       " -0.0089216735,\n",
       " 0.004883056,\n",
       " -0.05022572,\n",
       " -0.03656785,\n",
       " 0.054925203,\n",
       " 0.015567036,\n",
       " -0.05022572,\n",
       " 0.010280118,\n",
       " 0.009252107,\n",
       " 0.016521618,\n",
       " -0.010280118,\n",
       " -0.0135844415,\n",
       " 0.008995104,\n",
       " -0.029518625,\n",
       " 0.018283924,\n",
       " -0.011528418,\n",
       " -0.039651886,\n",
       " 0.029812343,\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utilities import embed_phrase, opensearch_bulk_load\n",
    "\n",
    "#test calling embed_phrase method from utilities file to get embedding of a given model.\n",
    "embed_phrase(\"Testing amazon bedrock models\", model_id, bedrock_client=bedrock_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ff02b",
   "metadata": {},
   "source": [
    "### Loading data in to opensearch\n",
    "Let's load data into opensearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfe8ca26",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk_content': 'AWS Docs as of 7/7/24 \\n\\nWhat is Amazon Bedrock?\\n\\nAmazon Bedrock is a fully managed service that makes high-performing foundation models (FMs) from leading AI startups and Amazon available for your use through a unified API. You can choose from a wide range of foundation models to find the model that is best suited for your use case. Amazon Bedrock also offers a broad set of capabilities to build generative AI applications with security, privacy, and responsible AI. Using Amazon Bedrock, you can easily experiment with and evaluate top foundation models for your use cases, privately customize them with your data using techniques such as fine-tuning and Retrieval Augmented Generation (RAG), and build agents that execute tasks using your enterprise systems and data sources.', 'chunk_vector': [-0.10175564, 0.023692032, 0.015285183, -0.03537428, -0.041051634, -0.018997299, 0.037121158, -0.04498211, -0.015612722, -0.029041847, -0.010044549, -0.032317244, -0.0012078023, -0.008188491, -0.032317244, 0.007096692, -0.047384065, -0.00884357, 0.06157745, 0.063324325, 0.00065507926, 0.055900097, 0.020198276, 0.040614914, 0.049130943, -0.039959833, -0.02653071, -0.04410867, 0.022927774, -0.010262908, -0.019215658, 0.027185788, -0.014302564, -0.011409297, 0.05131454, -0.03515592, 0.110926755, -0.0081339, -0.05415322, 0.050222743, 0.01834222, 0.045637187, -0.00069943356, -0.021726795, 0.0040396554, -0.035811, 0.030133646, 0.024893012, 0.006277843, 0.036029357, 0.06070401, 0.03515592, -0.006332433, 0.13363616, 0.00857062, -0.028168408, 0.06245089, -0.019543197, 0.044327028, 0.0011327412, -0.014084204, -0.02576645, -0.024237933, 0.050659463, -0.007042102, -0.03428248, 0.011245527, 0.03624772, -0.018560579, 0.03340904, -0.036902796, -0.014739283, -0.055463377, 0.0030297416, -0.08821734, -0.060267292, -0.084723584, 0.035592638, 0.0173596, 0.013811254, -0.010372088, -0.039086394, 0.03428248, -0.012173556, -0.03340904, -0.046292268, -0.0057865335, -0.016376982, 0.037994597, -0.015940262, 0.03515592, -0.0064143175, 0.039523114, 0.02598481, 0.08996422, -0.0537165, -0.00873439, 0.058083694, -0.020634996, -0.021726795, 0.03515592, 0.056336816, -0.007806361, -0.07642591, 0.0020471227, -0.023146134, 0.058520414, -0.0047766194, -0.0023200724, 0.049567662, 0.048475865, 0.019106477, -0.02543891, 0.0029751516, 0.064197764, -0.031662162, 0.08428686, -0.0017332305, -0.019215658, 0.020525817, 0.015721902, -0.035592638, -0.08210327, 0.106996275, -0.013429125, -0.039959833, -0.012009786, -0.028386768, 0.006059483, -0.027404148, 0.012828635, 0.0081339, -0.03384576, -0.03515592, -0.018997299, 0.04126999, -0.01812386, 0.041925073, 0.055463377, -0.049567662, 0.0031389215, 0.0012419211, 0.0080247205, -0.029260207, 0.049130943, 0.024893012, -0.009553239, -0.0081339, -0.020962536, -0.037121158, 0.021945154, -0.01725042, -0.06201417, -0.055463377, -0.014520924, -0.039304756, -0.022927774, 0.0073696417, 0.015831081, -0.015612722, -0.006141368, 0.002197245, -0.067254804, 0.011190937, -0.039959833, 0.013538305, -0.0014875758, -0.011300117, -0.014957643, 0.03515592, 0.049130943, -0.040396553, 0.030352006, 0.02598481, 0.018778939, -0.01725042, -0.024783831, 0.038431317, -0.07729935, 0.015831081, -0.0526247, 0.04367195, -0.002647612, -0.0025793745, 0.010481268, 0.038868036, -0.00851603, -0.0039031806, 0.021617616, 0.016158622, -0.05240634, 0.011245527, 0.01714124, -0.038212955, 0.029478567, 0.07249544, -0.047384065, -0.00835226, -0.012555686, -0.0325356, 0.037557878, -0.006987512, 0.005240634, 0.011736836, 0.022054335, 0.011463887, 0.030352006, 0.031225445, -0.030352006, -0.01746878, -0.018997299, -0.032317244, 0.0030297416, 0.010317498, -0.021508435, -0.040178195, -0.014957643, -0.020744177, 0.048694223, -0.049130943, -0.0155035425, 0.010426678, 0.041925073, 0.02653071, -0.01714124, -0.004421785, -0.012992405, 0.016595341, -0.013865844, -0.021726795, -0.00862521, 0.029478567, 0.005295224, -0.0048312093, -0.048475865, 0.013592894, -0.0016581693, 0.025329731, -0.005349814, 0.01714124, -0.021945154, 0.022381874, -0.024893012, -0.02598481, -0.014848463, 0.029478567, -0.01714124, -0.0064416127, -0.0073696417, -0.04410867, 0.057210255, -0.005267929, -0.022381874, 0.09083766, 0.049130943, 0.0033845762, 0.018560579, 0.03297232, 0.03428248, -0.009116519, -0.033190683, -0.008297671, 0.02565727, -0.023473673, 0.030570365, 0.0059503033, 0.011900607, 0.009334879, 0.006277843, 0.02543891, 0.009607829, 0.010426678, -0.0146301035, 0.03493756, 0.033627402, -0.00048107383, 0.0012487448, -0.044763748, 0.0077517712, -0.016813701, -0.019979917, 0.046292268, 0.020198276, 0.023801213, 0.04585555, -0.020525817, -0.024783831, 0.020089097, 0.028386768, -8.529678e-05, 0.0019788851, -0.04126999, -0.003043389, 0.0033163386, 0.02543891, -0.041051634, 0.054371577, 0.015612722, -0.032098882, 0.011736836, 0.024783831, -0.03515592, -0.007860951, 0.05306142, 0.038212955, -0.033627402, -0.0013647485, -0.016376982, 0.040614914, 0.0515329, -0.006059483, 0.020089097, 0.035811, -0.037994597, 0.024893012, 0.018888118, 0.050222743, -0.02598481, -0.007860951, -0.013156175, 0.028386768, 0.0012760398, -0.028605128, -0.0086798, -0.040396553, -0.014302564, -0.013265355, -0.040614914, -0.057646975, -0.005131454, -0.0046674395, -0.021945154, 0.029041847, -0.006332433, 0.01670452, -0.006851037, 0.064197764, 0.0033436336, -0.03515592, -0.014739283, 0.018451398, -0.003466461, 0.01714124, 0.029478567, 0.027404148, 0.012118966, 0.056336816, -0.007205872, 0.019215658, 0.0047766194, -0.002197245, 0.0033845762, 0.02620317, 0.032098882, -0.005404404, -0.018014679, -0.0155035425, 0.00211536, 0.037121158, -0.0055681737, 0.018888118, -0.006195958, -0.0097715985, -0.023146134, 0.021617616, -0.020853356, 8.060545e-05, -0.007260462, -0.031662162, -0.029260207, -0.044763748, 0.022381874, -0.018669758, -0.0024974896, 0.0014261621, 0.00096214766, 0.09476813, 0.012173556, 0.01714124, -0.028823487, -0.02707661, 0.056773536, -0.020962536, -0.00085637963, -0.048475865, 0.0064143175, -0.00060390116, -0.024783831, 0.013865844, 0.006905627, 0.0044490797, 0.035811, -0.024347112, 0.012118966, -0.059393853, -0.01757796, 0.029260207, 0.07948295, 0.00862521, -0.022927774, -0.0065780873, -0.0047493246, 0.050222743, 0.0537165, 0.04367195, 0.037121158, -0.006277843, -0.013865844, -0.0016104032, -0.027950048, -0.02543891, 0.005868418, 0.04170671, 0.055900097, 0.024565471, 0.005923008, -0.011846016, 0.022600234, -0.006086778, 0.023146134, 0.024019573, 0.06769152, -0.018888118, -0.024237933, 0.080793105, -0.019215658, 0.018997299, 0.046947345, -0.047384065, 0.0018424104, 0.03493756, -0.023692032, -0.02543891, 0.0515329, 0.016595341, -0.03493756, -0.006987512, 0.03428248, 0.0081339, 0.0047766194, -0.004530965, 0.01757796, -0.020089097, -0.05240634, -0.009826189, -0.03297232, -0.018997299, 0.009553239, 0.055463377, -0.0034528135, -0.0526247, -0.039304756, 0.002934209, -0.040178195, 0.002197245, 0.0064143175, 0.02707661, 0.038649675, -0.02685825, 0.0075880014, -0.015612722, -0.04454539, -0.02576645, -0.020744177, -0.05131454, 0.0057319435, -0.054371577, -0.046728987, 0.048694223, -0.023146134, -0.00878898, -0.04585555, -0.0022654824, 0.030133646, 0.032098882, -0.04323523, -0.0020471227, 0.01834222, -0.013538305, -0.06812824, 0.039959833, 0.00428531, -0.022927774, -0.0019788851, -0.0005936656, -0.025111372, 0.022054335, -0.066381365, -0.04389031, -0.000767671, -0.032753963, 0.03624772, 0.013865844, 0.03428248, 0.037994597, 0.00024394879, 0.041051634, -0.032753963, 0.022600234, -0.028168408, 0.039086394, 0.0004367195, -0.014520924, 0.04279851, -0.020962536, -0.015176003, 0.019870738, 0.028168408, 0.0031798638, 0.009225699, -0.03384576, 0.018451398, 0.058520414, 0.007096692, -0.047602426, -0.0017605255, -0.004258015, -0.006086778, 0.015066823, 0.039959833, -0.006223253, -0.0173596, -0.0022108925, -0.021617616, -0.014302564, -0.030133646, 0.039086394, 0.046292268, 0.03493756, 0.022163514, -0.009880778, -0.024237933, -0.011136347, 0.0011600362, 0.0347192, 0.049786024, -0.016376982, 0.039086394, -0.0526247, -0.013702074, 0.03537428, -0.056773536, -0.0037667057, 0.04498211, 0.004530965, 0.0526247, -0.039959833, 0.006141368, -0.004258015, 0.046728987, 0.045200467, -0.005349814, 0.04214343, 0.074242316, -0.023146134, 0.041488353, -0.01757796, 0.0020471227, -0.00824308, 0.037121158, 0.010317498, -0.0075880014, -0.05415322, -0.0033982235, 0.010917988, -0.049567662, 0.024347112, -0.0041488353, 0.0055954685, -0.00917111, 0.057646975, -0.006059483, 0.012282736, 0.054808296, -0.0033982235, -0.0155035425, 0.037776235, 0.029260207, 0.039959833, 0.020853356, 0.032098882, 0.0014875758, 0.026749069, 0.028823487, -0.012883225, -0.071185276, -0.013975024, -0.0515329, 0.04323523, 0.009007339, -0.040614914, 0.012555686, -0.023364494, -0.011900607, 0.0075880014, -0.0039577703, 0.01768714, 0.0016445218, 0.0097715985, -0.003602936, 0.023364494, 0.014193384, 0.012883225, -0.0066326773, 0.04279851, 0.008297671, 0.010808808, -0.021508435, 0.0694384, -0.06245089, 0.04345359, -0.022491055, -0.00031900994, -0.0086798, 0.027185788, 0.02653071, 0.05196962, -0.016158622, 0.029041847, -0.0020198277, -0.046728987, 0.00906193, -0.00015268123, 0.004940389, -0.002647612, -0.08122983, 0.012173556, 0.01812386, 0.024019573, -0.022818593, 0.010481268, 0.0162678, 0.018997299, 0.0033845762, 0.01714124, -0.06245089, -0.01692288, 0.067254804, 0.044327028, -0.01670452, -0.014848463, 0.011846016, 0.014193384, -0.039086394, -0.015066823, 0.0045036697, -0.022054335, 0.00206077, -0.045637187, -0.022381874, -0.02543891, -0.06070401, 0.055463377, 0.040833272, 0.007042102, 0.0162678, -0.0024974896, -0.005240634, 0.006195958, -0.004367195, 0.0026612594, -0.035592638, -0.009498649, 0.0012419211, 0.029915286, 0.04279851, -0.015940262, -0.023146134, -0.0067145624, 0.0039031806, 0.014957643, -0.014957643, 0.018997299, -0.01725042, 0.005158749, -0.021399256, -0.021399256, -0.031007085, 0.0064962027, 0.005213339, 0.00917111, -0.032098882, -0.0033845762, 0.040614914, -0.00835226, 0.024019573, -0.019434018, 0.041488353, 0.012555686, -0.03406412, 0.01714124, 0.038649675, 0.033190683, 0.0073696417, 0.046947345, -0.024565471, -0.005104159, 0.008297671, 0.021835975, -0.0077517712, -0.0073150517, -0.011682247, 0.0055954685, 0.022709414, -0.0067145624, 0.015285183, -0.072058715, -0.01757796, 0.009444059, 0.038649675, -0.037776235, -0.04498211, -0.01725042, -0.01714124, -0.0039031806, -0.05131454, 0.060267292, 0.02631235, 0.019543197, 0.018888118, -0.0526247, 0.0018424104, -0.005240634, -0.03515592, -0.0019515903, -0.0066326773, 0.021945154, -0.014302564, 0.009553239, 0.022818593, 0.058083694, 0.0064416127, 0.010972577, -0.0016581693, 0.045200467, 0.022381874, -0.022381874, 0.045637187, -0.07031184, -0.041925073, -0.019652378, -0.021508435, 0.04541883, 0.019870738, -0.022491055, 0.015612722, -0.01757796, -0.064197764, -0.041925073, 0.025329731, 0.058520414, -0.004530965, -0.005868418, 0.027950048, 0.013975024, -0.0526247, -0.00439449, 0.00033265742, -0.0018970004, -0.005923008, 0.0064416127, 0.0081339, -0.0075880014, 0.012555686, 0.021399256, -0.007096692, 0.0325356, 0.00406695, 0.0027431443, -0.010262908, -0.018669758, -0.00895275, -0.00042307202, 0.013592894, -0.038649675, 0.010972577, 0.010481268, 0.00906193, 0.0162678, 0.007096692, 0.030352006, -0.028823487, -0.022163514, -0.03384576, -0.041488353, -0.00039748297, 2.9214147e-05, 0.05240634, -0.047384065, 0.011354707, -0.01812386, -0.07817279, 0.022818593, 0.0650712, 0.013538305, 0.048475865, 0.019215658, 0.040614914, -0.028386768, -0.0032890437, 0.05415322, -0.010099138, 7.9326004e-05, -0.02565727, -0.039959833, 0.0037667057, 0.00873439, 0.031880524, -0.0347192, 0.05087782, -0.021835975, -0.007806361, -0.00439449, 0.05306142, 0.047384065, -0.029041847, -0.0074788216, -0.0007096692, 0.022709414, 0.024893012, 0.039086394, -0.024893012, 0.0007744947, 0.003602936, -0.00878898, 0.03428248, -0.008079311, 0.041051634, 0.038212955, -0.013429125, 0.013538305, -0.024019573, -0.0033572812, -0.02685825, -0.012828635, -0.0024428996, -0.030352006, -0.019979917, -0.009498649, -0.027622508, 0.01714124, -0.05306142, -0.05415322, -0.005104159, -0.017796319, 0.02576645, -0.01692288, 0.049567662, -0.003466461, -0.027404148, 0.015176003, -0.044763748, -0.016049441, 0.037121158, -0.02543891, 0.04367195, -0.005295224, -0.020198276, -0.055900097, 0.057210255, -0.022381874, 0.055900097, 0.019543197, 0.06245089, 0.030352006, 0.0010986225, 0.037121158, -0.035811, 0.010317498, 0.035811, -0.016376982, -0.030352006, -0.012009786, -0.02653071, 0.006932922, 0.024893012, 0.015721902, -0.024347112, 0.02543891, 0.041488353, 0.0059503033, 0.013265355, 0.006905627, 0.06856496, -0.04410867, -0.047384065, 0.011463887, 0.027622508, 0.032098882, 0.031662162, 0.0004742501, -0.015394363, -0.0015012233, 0.00851603, -0.0014125146, -0.00878898, -0.074242316, -0.0073696417, -0.0173596, -0.012719455, 0.022927774, 0.006987512, -0.092584535, -0.0025520795, 0.015066823, -0.010262908, 0.02653071, -0.024893012, -0.031443805, -0.03624772, -0.014957643, -0.02565727, -0.048039146, 0.0017332305, -0.00835226, -0.015394363, -0.0054316986, 0.010699628, -0.01714124, -0.005104159, -0.058520414, 0.018669758, 0.014084204, 0.02576645, 0.018560579, 0.04279851, 0.031007085, 0.015721902, -0.0075334115, -0.0037121158, 0.007806361, 0.005404404, -0.024237933, 0.041051634, 0.0047493246, -0.01648616, 0.013374534, -0.032317244, -0.0004742501, 0.0179055, 0.03384576, 0.01692288, -0.041488353, 0.025111372, -0.0012623923, -0.07074856, 0.019979917, -0.057646975, -0.022054335, 0.006141368, 0.036466077, 0.04585555, 0.03384576, 0.016595341, 0.0074242316, 0.014520924, -0.040833272, -0.020744177, 0.04258015, -0.056773536, -0.025111372, 0.018778939, -0.0007233167, -0.021399256, -0.008297671, -0.016595341, -0.0048857993, -0.003466461, -0.00097579515, 0.0076425914, 0.024019573, -0.0016718168, 0.03450084, 0.057646975, -0.00071308104, -0.046947345, -0.00873439, 0.006195958, 0.013374534, -0.01757796, -0.03515592, 0.053498138, -0.031443805, -0.0063597276, -0.059393853, -0.019434018, 0.024237933, -0.037121158, -0.027622508, 0.013156175, 0.021290075, 0.055900097, -0.0146301035, -0.0055408785, -0.017796319, -0.065507926, -0.009553239, 0.00014585748, 0.0019515903, 0.021835975, -0.01746878, 0.013592894, -0.010699628, -0.005923008, 0.014520924, 0.02685825, 0.013265355, 0.02576645, 0.056773536, -0.031225445, -0.009334879, 0.009498649, -0.0016035794, -0.005868418, 0.01670452, -0.0014602809, 0.016595341, -0.019215658, -0.020307457, 0.006086778, 0.04389031, 0.013865844, -0.029260207, -0.039304756]}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'errors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(chunks[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#load data into opensearch - every chunk will be separate opensearch record/document.\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mopensearch_bulk_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maos_client\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SageMaker/data-foundation-gen-ai-aws-vector-databases/advance-rag/utilities.py:42\u001b[0m, in \u001b[0;36mopensearch_bulk_load\u001b[0;34m(data, index_name, aos_client)\u001b[0m\n\u001b[1;32m     39\u001b[0m response \u001b[38;5;241m=\u001b[39m aos_client\u001b[38;5;241m.\u001b[39mbulk(bulk_data)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Check the response\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErrors occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'errors'"
     ]
    }
   ],
   "source": [
    "#process all the chunks and get embeddings from Bedrock for each text chunk\n",
    "chunks = []\n",
    "\n",
    "for doc in docs:\n",
    "    chunks.append({\"chunk_content\": doc.page_content, \"chunk_vector\": embed_phrase(doc.page_content, model_id, bedrock_client)})\n",
    "\n",
    "print(chunks[0])\n",
    "\n",
    "#load data into opensearch - every chunk will be separate opensearch record/document.\n",
    "opensearch_bulk_load(chunks, index_name, aos_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84d683e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_opensearch_with_semantic_search(phrase, model_id, bedrock_client, n=3 ):\n",
    "    search_vector = embed_phrase(phrase, model_id=model_id, bedrock_client=bedrock_client)\n",
    "    osquery={\n",
    "        \"_source\": {\n",
    "            \"exclude\": [ \"chunk_vector\" ]\n",
    "        },\n",
    "        \n",
    "      \"size\": n,\n",
    "      \"query\": {\n",
    "        \"knn\": {\n",
    "          \"chunk_vector\": {\n",
    "            \"vector\":search_vector,\n",
    "            \"k\":n\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    res = aos_client.search(index=index_name, \n",
    "                           body=osquery,\n",
    "                           stored_fields=[\"chunk_content\"],\n",
    "                           explain = True)\n",
    "    top_result = res['hits']['hits']\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for entry in top_result:\n",
    "        result = {\n",
    "            \"chunk_content\":entry['_source']['chunk_content'],\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f994693c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"chunk_content\": \"The following diagram shows an example VPC. The VPC has one subnet in each of the Availability Zones in the Region, EC2 instances in each subnet, and an internet gateway to allow communication between the resources in your VPC and the internet.\\n\\nFeatures\\nThe following features help you configure a VPC to provide the connectivity that your applications need:\\n\\nVirtual private clouds (VPC)\\nA VPC is a virtual network that closely resembles a traditional network that you'd operate in your own data center. After you create a VPC, you can add subnets.\\n\\nSubnets\\nA subnet is a range of IP addresses in your VPC. A subnet must reside in a single Availability Zone. After you add subnets, you can deploy AWS resources in your VPC.\"\n",
      "    },\n",
      "    {\n",
      "        \"chunk_content\": \"Transit gateways\\nUse a transit gateway, which acts as a central hub, to route traffic between your VPCs, VPN connections, and AWS Direct Connect connections.\\n\\nVPC Flow Logs\\nA flow log captures information about the IP traffic going to and from network interfaces in your VPC.\\n\\nVPN connections\\nConnect your VPCs to your on-premises networks using AWS Virtual Private Network (AWS VPN).\\n\\n\\nAmazon Textrac docs:\\nWhat is Amazon Textract? Amazon Textract helps you add document text detection and analysis to your applications. Using Amazon Textract, you can do the following:\\n\\nDetect typed and handwritten text in a variety of documents, including financial reports, medical records, and tax forms.\\n\\nExtract text, forms, and tables from documents with structured data, using the Amazon Textract Document Analysis API.\\n\\nSpecify and extract information from documents using the Queries feature within the Amazon Textract Analyze Document API.\\n\\nProcess invoices and receipts with the AnalyzeExpense API.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "question_on_s3_docs=\"What VPN connections do ?\"\n",
    "\n",
    "example_request = retrieve_opensearch_with_semantic_search(phrase=question_on_s3_docs, model_id=model_id, bedrock_client=bedrock_client, n=2)\n",
    "print(json.dumps(example_request, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55efcf0f-1bb6-49d9-9ad5-9e5bb641f16d",
   "metadata": {},
   "source": [
    "## Reranking the retrieved context with cross-encoder models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47d0d495-2727-407b-8bfa-dfdab1cc3d6a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence_transformers) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence_transformers) (2.1.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence_transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence_transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence_transformers) (0.23.4)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sentence_transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.34.0->sentence_transformers)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence_transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m134.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, tokenizers, transformers, sentence_transformers\n",
      "Successfully installed regex-2024.5.15 sentence_transformers-3.0.1 tokenizers-0.19.1 transformers-4.42.4\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "15893870-3d86-4fa9-a67f-f6b2f7389df3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a48cc806-bffa-440c-9aef-eae52ecd9d91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03387ba91774d53bb4fc8a5d353fe30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62a3d93104441859e14ba7792745009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192be5a3f2154b12a8d312c4a2808acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ec1ff1edab4dfc9be781d8a8063294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db12d5e2968e456e8439fa84513034d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d2bf660-f95e-4733-a116-fe57a46eb6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What do VPN connection do?\"\n",
    "retrieved_chunks = retrieve_opensearch_with_semantic_search(phrase=question_on_s3_docs, model_id=model_id, bedrock_client=bedrock_client, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e652a76a-2726-4880-b4e8-674590397c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the chunk list\n",
    "chunk_list = []\n",
    "\n",
    "# Loop through each chunk in the data\n",
    "for item in retrieved_chunks:\n",
    "    # Split the chunk content into paragraphs\n",
    "    chunk = item['chunk_content']\n",
    "    chunk_list.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d0b56481-0c1c-4df7-9c59-063b70149de5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The following diagram shows an example VPC. The VPC has one subnet in each of the Availability Zones in the Region, EC2 instances in each subnet, and an internet gateway to allow communication between the resources in your VPC and the internet.\\n\\nFeatures\\nThe following features help you configure a VPC to provide the connectivity that your applications need:\\n\\nVirtual private clouds (VPC)\\nA VPC is a virtual network that closely resembles a traditional network that you'd operate in your own data center. After you create a VPC, you can add subnets.\\n\\nSubnets\\nA subnet is a range of IP addresses in your VPC. A subnet must reside in a single Availability Zone. After you add subnets, you can deploy AWS resources in your VPC.\",\n",
       " 'Transit gateways\\nUse a transit gateway, which acts as a central hub, to route traffic between your VPCs, VPN connections, and AWS Direct Connect connections.\\n\\nVPC Flow Logs\\nA flow log captures information about the IP traffic going to and from network interfaces in your VPC.\\n\\nVPN connections\\nConnect your VPCs to your on-premises networks using AWS Virtual Private Network (AWS VPN).\\n\\n\\nAmazon Textrac docs:\\nWhat is Amazon Textract? Amazon Textract helps you add document text detection and analysis to your applications. Using Amazon Textract, you can do the following:\\n\\nDetect typed and handwritten text in a variety of documents, including financial reports, medical records, and tax forms.\\n\\nExtract text, forms, and tables from documents with structured data, using the Amazon Textract Document Analysis API.\\n\\nSpecify and extract information from documents using the Queries feature within the Amazon Textract Analyze Document API.\\n\\nProcess invoices and receipts with the AnalyzeExpense API.']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0e49e9da-2a95-4a61-a6a2-aa4c390396df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_chunk_pairs = [(query, chunk) for chunk in chunk_list]\n",
    "scores = model.predict(query_chunk_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ed8f1c31-30a8-4a9e-b22e-13e9eaec483e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.2159215,  3.8904986], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "13e50a10-f3ab-4441-82c2-a67b993d657c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sort_chunks_by_scores(chunk_list, scores):\n",
    "    # Ensure scores is a numpy array\n",
    "    scores = np.array(scores)\n",
    "    \n",
    "    # Pair each chunk with its score\n",
    "    paired = list(zip(scores, chunk_list))\n",
    "    \n",
    "    # Sort the pairs based on scores in descending order\n",
    "    sorted_pairs = sorted(paired, key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Extract the sorted chunks\n",
    "    sorted_chunks = [chunk for _, chunk in sorted_pairs]\n",
    "    \n",
    "    return sorted_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "99330d18-6e2e-4f5e-8d59-8870188325ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reranked_chunks = sort_chunks_by_scores(chunk_list, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715be81-17f3-4691-81e8-2cee20443fc4",
   "metadata": {},
   "source": [
    "## Building a RAG pipeline with Langchain\n",
    "Work in Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7f8e855-b57b-4cf2-8672-72c30153e649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "sonnet_llm = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    model_kwargs=dict(temperature=0),\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44029fa8-21ca-46e2-bede-c559ed6fbded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "rag_template = \"\"\"\\\n",
    "Use the following context to answer the user's query. If you cannot answer, please respond with 'I don't know'.\n",
    "\n",
    "User's Query:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8fdd6b5-94a1-487d-bc6f-c672a94237fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_opensearch_with_semantic_search(phrase, model_id='anthropic.claude-3-sonnet-20240229-v1:0', bedrock_client=bedrock_client, n=3 ):\n",
    "    search_vector = embed_phrase(phrase, model_id=model_id, bedrock_client=bedrock_client)\n",
    "    osquery={\n",
    "        \"_source\": {\n",
    "            \"exclude\": [ \"chunk_vector\" ]\n",
    "        },\n",
    "        \n",
    "      \"size\": n,\n",
    "      \"query\": {\n",
    "        \"knn\": {\n",
    "          \"chunk_vector\": {\n",
    "            \"vector\":search_vector,\n",
    "            \"k\":n\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    res = aos_client.search(index=index_name, \n",
    "                           body=osquery,\n",
    "                           stored_fields=[\"chunk_content\"],\n",
    "                           explain = True)\n",
    "    top_result = res['hits']['hits']\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for entry in top_result:\n",
    "        result = {\n",
    "            \"chunk_content\":entry['_source']['chunk_content'],\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "576d4b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\" : retrieve_opensearch_with_semantic_search, \"question\" : RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | sonnet_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cdb041f-c4ca-4b29-8a36-1402f43049dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValidationException",
     "evalue": "An error occurred (ValidationException) when calling the InvokeModel operation: Malformed input request: #: required key [prompt] not found#: required key [max_tokens_to_sample] not found#: extraneous key [inputText] is not permitted, please reformat your input and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrag_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDescribe the Feature-based Approach with BERT?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/base.py:2570\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2566\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m   2567\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2568\u001b[0m )\n\u001b[1;32m   2569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2570\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2571\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2572\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/base.py:3217\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   3204\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3205\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3206\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m   3207\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3215\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3216\u001b[0m         ]\n\u001b[0;32m-> 3217\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3218\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/base.py:3217\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3204\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3205\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3206\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m   3207\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3215\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3216\u001b[0m         ]\n\u001b[0;32m-> 3217\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3218\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/base.py:4050\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4048\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this runnable synchronously.\"\"\"\u001b[39;00m\n\u001b[1;32m   4049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4050\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4051\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4052\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4053\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4054\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4055\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4056\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   4058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4060\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/base.py:1594\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1591\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1592\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1593\u001b[0m         Output,\n\u001b[0;32m-> 1594\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1596\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1597\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1598\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1599\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1602\u001b[0m     )\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1604\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/config.py:380\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    379\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/base.py:3918\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3916\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m   3917\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3918\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3919\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   3920\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3921\u001b[0m \u001b[38;5;66;03m# If the output is a runnable, invoke it\u001b[39;00m\n\u001b[1;32m   3922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/langchain_core/runnables/config.py:380\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    379\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m, in \u001b[0;36mretrieve_opensearch_with_semantic_search\u001b[0;34m(phrase, model_id, bedrock_client, n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve_opensearch_with_semantic_search\u001b[39m(phrase, model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manthropic.claude-3-sonnet-20240229-v1:0\u001b[39m\u001b[38;5;124m'\u001b[39m, bedrock_client\u001b[38;5;241m=\u001b[39mbedrock_client, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m ):\n\u001b[0;32m----> 2\u001b[0m     search_vector \u001b[38;5;241m=\u001b[39m \u001b[43membed_phrase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbedrock_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbedrock_client\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     osquery\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexclude\u001b[39m\u001b[38;5;124m\"\u001b[39m: [ \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m ]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m       }\n\u001b[1;32m     17\u001b[0m     }\n\u001b[1;32m     19\u001b[0m     res \u001b[38;5;241m=\u001b[39m aos_client\u001b[38;5;241m.\u001b[39msearch(index\u001b[38;5;241m=\u001b[39mindex_name, \n\u001b[1;32m     20\u001b[0m                            body\u001b[38;5;241m=\u001b[39mosquery,\n\u001b[1;32m     21\u001b[0m                            stored_fields\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_content\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     22\u001b[0m                            explain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/SageMaker/data-foundation-gen-ai-aws-vector-databases/advance-rag/utilities.py:13\u001b[0m, in \u001b[0;36membed_phrase\u001b[0;34m(text, model_id, bedrock_client)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Prepare the request payload\u001b[39;00m\n\u001b[1;32m     11\u001b[0m request_payload \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputText\u001b[39m\u001b[38;5;124m\"\u001b[39m: text})\n\u001b[0;32m---> 13\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mbedrock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_payload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontentType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontentType\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Extract the embedding from the response\u001b[39;00m\n\u001b[1;32m     16\u001b[0m response_body \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread())\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/client.py:1021\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mValidationException\u001b[0m: An error occurred (ValidationException) when calling the InvokeModel operation: Malformed input request: #: required key [prompt] not found#: required key [max_tokens_to_sample] not found#: extraneous key [inputText] is not permitted, please reformat your input and try again."
     ]
    }
   ],
   "source": [
    "rag_chain.invoke({\"question\":\"Describe the Feature-based Approach with BERT?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac84c985-2520-4b68-b96d-b7f66ba4dfef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
